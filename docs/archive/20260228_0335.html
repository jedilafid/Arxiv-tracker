<!doctype html>
<html><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1">
<title>arXiv 论文速递</title><style>
:root {
  --bg:#f8fafc; --card:#ffffff; --text:#0f172a; --muted:#667085; --border:#e5e7eb; --acc:#2563eb;
}
:root[data-theme="dark"] {
  --bg:#0b0f17; --card:#111827; --text:#e5e7eb; --muted:#9ca3af; --border:#1f2937; --acc:#2563eb;
}
*{box-sizing:border-box} body{margin:0;background:var(--bg);color:var(--text);
  font-family:ui-sans-serif,system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial;line-height:1.6;}
.container{max-width:900px;margin:0 auto;padding:18px;}
.header{display:flex;gap:10px;justify-content:space-between;align-items:center;margin:8px 0 16px;flex-wrap:wrap}
h1{font-size:22px;margin:0}
.badge{font-size:12px;color:#111827;background:var(--acc);padding:2px 8px;border-radius:999px}
.card{background:var(--card);border:1px solid var(--border);border-radius:16px;padding:16px 18px;margin:14px 0;box-shadow:0 1px 2px rgba(0,0,0,.04)}
.title{font-weight:700;margin:0 0 6px 0;font-size:18px}
.meta-line{color:var(--muted);font-size:13px;margin:2px 0}
.links a{color:var(--acc);text-decoration:none;margin-right:12px}
.detail{margin-top:10px;background:rgba(2,6,23,.03);border:1px solid var(--border);border-radius:10px;padding:8px 10px}
summary{cursor:pointer;color:var(--acc)}
.mono{white-space:pre-wrap;background:rgba(2,6,23,.03);border:1px solid var(--border);padding:10px;border-radius:10px}
.row{display:grid;grid-template-columns:1fr;gap:12px}
@media (min-width: 860px) {
  .row-2{grid-template-columns:1fr 1fr}
}
.footer{color:var(--muted);font-size:13px;margin:20px 0 10px}
.hr{height:1px;background:var(--border);margin:14px 0}
.history-list a{display:block;color:var(--acc);text-decoration:none;margin:4px 0}
.controls{display:flex;gap:8px;align-items:center}
.btn{border:1px solid var(--border);background:var(--card);padding:6px 10px;border-radius:10px;cursor:pointer;color:var(--text)}
.btn:hover{border-color:var(--acc)}
</style>
<script>
(function() {
  const root = document.documentElement;
  function apply(t) {
    if (t==='dark') root.setAttribute('data-theme','dark');
    else if (t==='light') root.removeAttribute('data-theme');
    else {
      if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches)
        root.setAttribute('data-theme','dark');
      else root.removeAttribute('data-theme');
    }
  }
  let t = localStorage.getItem('theme') || 'light';
  if (!['light','dark','auto'].includes(t)) t='light';
  apply(t);
  window.__toggleTheme = function() {
    let cur = localStorage.getItem('theme') || 'light';
    if (cur==='light') cur='dark';
    else if (cur==='dark') cur='auto';
    else cur='light';
    localStorage.setItem('theme', cur);
    apply(cur);
    const el=document.getElementById('theme-label');
    if(el) el.textContent = cur.toUpperCase();
  }
  window.__expandAll = function(open) {
    document.querySelectorAll('details').forEach(d => d.open = !!open);
  }
})();
</script>
</head>
<body>
  <div class="container">
    <div class="header">
      <h1>arXiv 论文速递</h1>
      <div style="display:flex;gap:10px;align-items:center">
        
<div class="controls">
  <button class="btn" onclick="__toggleTheme()">Theme: <span id="theme-label" style="margin-left:6px">AUTO</span></button>
  <button class="btn" onclick="__expandAll(true)">Expand All</button>
  <button class="btn" onclick="__expandAll(false)">Collapse All</button>
</div>

        <span class="badge">2026-02-28 03:35</span>
      </div>
    </div>
    <div class="hr"></div>
    <div>Snapshot: 20260228_0335</div>
    <div class="row"><div class="card">
<div class="title">ODEBrain: Continuous-Time EEG Graph for Modeling Dynamic Brain Networks</div>
<div class="meta-line">Authors: Haohui Jia, Zheng Chen, Lingwei Zhu, Rikuto Kotoge, Jathurshan Pradeepkumar, Yasuko Matsubara, Jimeng Sun, Yasushi Sakurai, Takashi Matsubara</div>
<div class="meta-line">First: 2026-02-26T17:59:10+00:00 · Latest: 2026-02-26T17:59:10+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.23285v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.23285v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Modeling neural population dynamics is crucial for foundational neuroscientific research and various clinical applications. Conventional latent variable methods typically model continuous brain dynamics through discretizing time with recurrent architecture, which necessarily results in compounded cumulative prediction errors and failure of capturing instantaneous, nonlinear characteristics of EEGs. We propose ODEBRAIN, a Neural ODE latent dynamic forecasting framework to overcome these challenges by integrating spatio-temporal-frequency features into spectral graph nodes, followed by a Neural ODE modeling the continuous latent dynamics. Our design ensures that latent representations can capture stochastic variations of complex brain states at any given time point. Extensive experiments verify that ODEBRAIN can improve significantly over existing methods in forecasting EEG dynamics with enhanced robustness and generalization capabilities.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Modeling neural population dynamics is crucial for foundational neuroscientific research and various clinical applications.</div>
</details>
</div>
<div class="card">
<div class="title">Spatio-Temporal Token Pruning for Efficient High-Resolution GUI Agents</div>
<div class="meta-line">Authors: Zhou Xu, Bowen Zhou, Qi Wang, Shuwen Feng, Jingyu Xiao</div>
<div class="meta-line">First: 2026-02-26T17:12:40+00:00 · Latest: 2026-02-26T17:12:40+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.23235v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.23235v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Pure-vision GUI agents provide universal interaction capabilities but suffer from severe efficiency bottlenecks due to the massive spatiotemporal redundancy inherent in high-resolution screenshots and historical trajectories. We identify two critical misalignments in existing compression paradigms: the temporal mismatch, where uniform history encoding diverges from the agent&#x27;s &quot;fading memory&quot; attention pattern, and the spatial topology conflict, where unstructured pruning compromises the grid integrity required for precise coordinate grounding, inducing spatial hallucinations. To address these challenges, we introduce GUIPruner, a training-free framework tailored for high-resolution GUI navigation. It synergizes Temporal-Adaptive Resolution (TAR), which eliminates historical redundancy via decay-based resizing, and Stratified Structure-aware Pruning (SSP), which prioritizes interactive foregrounds and semantic anchors while safeguarding global layout. Extensive evaluations across diverse benchmarks demonstrate that GUIPruner consistently achieves state-of-the-art performance, effectively preventing the collapse observed in large-scale models under high compression. Notably, on Qwen2-VL-2B, our method delivers a 3.4x reduction in FLOPs and a 3.3x speedup in vision encoding latency while retaining over 94% of the original performance, enabling real-time, high-precision navigation with minimal resource consumption.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Pure-vision GUI agents provide universal interaction capabilities but suffer from severe efficiency bottlenecks due to the massive spatiotemporal redundancy inherent in high-resolution screenshots and historical trajectories.</div>
</details>
</div>
<div class="card">
<div class="title">SODAs: Sparse Optimization for the Discovery of Differential and Algebraic Equations</div>
<div class="meta-line">Authors: Manu Jayadharan, Christina Catlett, Arthur N. Montanari, Niall M. Mangan</div>
<div class="meta-line">First: 2025-03-08T00:29:00+00:00 · Latest: 2026-02-26T17:05:08+00:00</div>
<div class="meta-line">Comments: 22 pages, 5 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2503.05993v2">Abs</a> · <a href="https://arxiv.org/pdf/2503.05993v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Differential-algebraic equations (DAEs) integrate ordinary differential equations (ODEs) with algebraic constraints, providing a fundamental framework for developing models of dynamical systems characterized by timescale separation, conservation laws, and physical constraints. While sparse optimization has revolutionized model development by allowing data-driven discovery of parsimonious models from a library of possible equations, existing approaches for dynamical systems assume DAEs can be reduced to ODEs by eliminating variables before model discovery. This assumption limits the applicability of such methods for DAE systems with unknown constraints and time scales. We introduce Sparse Optimization for Differential-Algebraic Systems (SODAs), a data-driven method for the identification of DAEs in their explicit form. By discovering the algebraic and dynamic components sequentially without prior identification of the algebraic variables, this approach leads to a sequence of convex optimization problems. It has the advantage of discovering interpretable models that preserve the structure of the underlying physical system. To this end, SODAs improves numerical stability when handling high correlations between library terms, caused by near-perfect algebraic relationships, by iteratively refining the conditioning of the candidate library. We demonstrate the performance of our method on biological, mechanical, and electrical systems, showcasing its robustness to noise in both simulated time series and real-time experimental data.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Differential-algebraic equations (DAEs) integrate ordinary differential equations (ODEs) with algebraic constraints, providing a fundamental framework for developing models of dynamical systems characterized by timescale separation, conservation laws, and physical constraints.</div>
</details>
</div>
<div class="card">
<div class="title">PATRA: Pattern-Aware Alignment and Balanced Reasoning for Time Series Question Answering</div>
<div class="meta-line">Authors: Junkai Lu, Peng Chen, Xingjian Wu, Yang Shu, Chenjuan Guo, Christian S. Jensen, Bin Yang</div>
<div class="meta-line">First: 2026-02-26T16:20:03+00:00 · Latest: 2026-02-26T16:20:03+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.23161v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.23161v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Time series reasoning demands both the perception of complex dynamics and logical depth. However, existing LLM-based approaches exhibit two limitations: they often treat time series merely as text or images, failing to capture the patterns like trends and seasonalities needed to answer specific questions; and when trained on a mix of simple and complex tasks, simpler objectives often dominate the learning process, hindering the development of deep reasoning capabilities. To address these limitations, we propose the Pattern-Aware Alignment and Balanced Reasoning model (PATRA), introducing a pattern-aware mechanism that extracts trend and seasonality patterns from time series to achieve deep alignment. Furthermore, we design a task-aware balanced reward to harmonize learning across tasks of varying difficulty, incentivizing the generation of coherent Chains of Thought. Extensive experiments show that PATRA outperforms strong baselines across diverse Time Series Question Answering (TSQA) tasks, demonstrating superior cross-modal understanding and reasoning capability.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Time series reasoning demands both the perception of complex dynamics and logical depth.</div>
</details>
</div>
<div class="card">
<div class="title">RhythmBERT: A Self-Supervised Language Model Based on Latent Representations of ECG Waveforms for Heart Disease Detection</div>
<div class="meta-line">Authors: Xin Wang, Burcu Ozek, Aruna Mohan, Amirhossein Ravari, Or Zilbershot, Fatemeh Afghah</div>
<div class="meta-line">First: 2026-02-26T14:45:29+00:00 · Latest: 2026-02-26T14:45:29+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.23060v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.23060v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Electrocardiogram (ECG) analysis is crucial for diagnosing heart disease, but most self-supervised learning methods treat ECG as a generic time series, overlooking physiologic semantics and rhythm-level structure. Existing contrastive methods utilize augmentations that distort morphology, whereas generative approaches employ fixed-window segmentation, which misaligns cardiac cycles. To address these limitations, we propose RhythmBERT, a generative ECG language model that considers ECG as a language paradigm by encoding P, QRS, and T segments into symbolic tokens via autoencoder-based latent representations. These discrete tokens capture rhythm semantics, while complementary continuous embeddings retain fine-grained morphology, enabling a unified view of waveform structure and rhythm. RhythmBERT is pretrained on approximately 800,000 unlabeled ECG recordings with a masked prediction objective, allowing it to learn contextual representations in a label-efficient manner. Evaluations show that despite using only a single lead, RhythmBERT achieves comparable or superior performance to strong 12-lead baselines. This generalization extends from prevalent conditions such as atrial fibrillation to clinically challenging cases such as subtle ST-T abnormalities and myocardial infarction. Our results suggest that considering ECG as structured language offers a scalable and physiologically aligned pathway for advancing cardiac analysis.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Electrocardiogram (ECG) analysis is crucial for diagnosing heart disease, but most self-supervised learning methods treat ECG as a generic time series, overlooking physiologic semantics and rhythm-level structure.</div>
</details>
</div>
<div class="card">
<div class="title">Benchmarking IoT Time-Series AD with Event-Level Augmentations</div>
<div class="meta-line">Authors: Dmitry Zhevnenko, Ilya Makarov, Aleksandr Kovalenko, Fedor Meshchaninov, Anton Kozhukhov, Vladislav Travnikov, Makar Ippolitov, Kirill Yashunin, Iurii Katser</div>
<div class="meta-line">First: 2026-02-17T09:45:44+00:00 · Latest: 2026-02-26T13:58:16+00:00</div>
<div class="meta-line">Comments: https://underline.io/events/521/sessions/21822/lecture/143905-benchmarking-iot-time-series-ad-with-event-level-augmentations?tab=poster</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.15457v2">Abs</a> · <a href="https://arxiv.org/pdf/2602.15457v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a> · <a href="https://underline.io/events/521/sessions/21822/lecture/143905-benchmarking-iot-time-series-ad-with-event-level-augmentations?tab=poster">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Anomaly detection (AD) for safety-critical IoT time series should be judged at the event level: reliability and earliness under realistic perturbations. Yet many studies still emphasize point-level results on curated base datasets, limiting value for model selection in practice. We introduce an evaluation protocol with unified event-level augmentations that simulate real-world issues: calibrated sensor dropout, linear and log drift, additive noise, and window shifts. We also perform sensor-level probing via mask-as-missing zeroing with per-channel influence estimation to support root-cause analysis. We evaluate 14 representative models on five public anomaly datasets (SWaT, WADI, SMD, SKAB, TEP) and two industrial datasets (steam turbine, nuclear turbogenerator) using unified splits and event aggregation. There is no universal winner: graph-structured models transfer best under dropout and long events (e.g., on SWaT under additive noise F1 drops 0.804-&gt;0.677 for a graph autoencoder, 0.759-&gt;0.680 for a graph-attention variant, and 0.762-&gt;0.756 for a hybrid graph attention model); density/flow models work well on clean stationary plants but can be fragile to monotone drift; spectral CNNs lead when periodicity is strong; reconstruction autoencoders become competitive after basic sensor vetting; predictive/hybrid dynamics help when faults break temporal dependencies but remain window-sensitive. The protocol also informs design choices: on SWaT under log drift, replacing normalizing flows with Gaussian density reduces high-stress F1 from ~0.75 to ~0.57, and fixing a learned DAG gives a small clean-set gain (~0.5-1.0 points) but increases drift sensitivity by ~8x.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Anomaly detection (AD) for safety-critical IoT time series should be judged at the event level: reliability and earliness under realistic perturbations.</div>
</details>
</div>
<div class="card">
<div class="title">A Data-Driven Approach to Support Clinical Renal Replacement Therapy</div>
<div class="meta-line">Authors: Alice Balboni, Luis Escobar, Andrea Manno, Fabrizio Rossi, Maria Cristina Ruffa, Gianluca Villa, Giordano D&#x27;Aloisio, Antonio Consolo</div>
<div class="meta-line">First: 2026-02-26T11:47:22+00:00 · Latest: 2026-02-26T11:47:22+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.22902v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.22902v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">This study investigates a data-driven machine learning approach to predict membrane fouling in critically ill patients undergoing Continuous Renal Replacement Therapy (CRRT). Using time-series data from an ICU, 16 clinically selected features were identified to train predictive models. To ensure interpretability and enable reliable counterfactual analysis, the researchers adopted a tabular data approach rather than modeling temporal dependencies directly. Given the imbalance between fouling and non-fouling cases, the ADASYN oversampling technique was applied to improve minority class representation. Random Forest, XGBoost, and LightGBM models were tested, achieving balanced performance with 77.6% sensitivity and 96.3% specificity at a 10% rebalancing rate. Results remained robust across different forecasting horizons. Notably, the tabular approach outperformed LSTM recurrent neural networks, suggesting that explicit temporal modeling was not necessary for strong predictive performance. Feature selection further reduced the model to five key variables, improving simplicity and interpretability with minimal loss of accuracy. A Shapley value-based counterfactual analysis was applied to the best-performing model, successfully identifying minimal input changes capable of reversing fouling predictions. Overall, the findings support the viability of interpretable machine learning models for predicting membrane fouling during CRRT. The integration of prediction and counterfactual analysis offers practical clinical value, potentially guiding therapeutic adjustments to reduce fouling risk and improve patient management.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This study investigates a data-driven machine learning approach to predict membrane fouling in critically ill patients undergoing Continuous Renal Replacement Therapy (CRRT).</div>
</details>
</div>
<div class="card">
<div class="title">Mixing It Up: Exploring Mixer Networks for Irregular Multivariate Time Series Forecasting</div>
<div class="meta-line">Authors: Christian Klötergens, Tim Dernedde, Lars Schmidt-Thieme, Vijaya Krishna Yalavarthi</div>
<div class="meta-line">First: 2025-02-17T14:06:36+00:00 · Latest: 2026-02-26T10:04:01+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2502.11816v3">Abs</a> · <a href="https://arxiv.org/pdf/2502.11816v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Forecasting irregularly sampled multivariate time series with missing values (IMTS) is a fundamental challenge in domains such as healthcare, climate science, and biology. While recent advances in vision and time series forecasting have shown that lightweight MLP-based architectures (e.g., MLP-Mixer, TSMixer) can rival attention-based models in both accuracy and efficiency, their applicability to irregular and sparse time series remains unexplored. In this paper, we propose IMTS-Mixer, a novel architecture that adapts the principles of Mixer models to the IMTS setting. IMTS-Mixer introduces two key components: (1) ISCAM, a channel-wise encoder that transforms irregular observations into fixed-size vectors using simple MLPs, and (2) ConTP, a continuous time decoder that supports forecasting at arbitrary time points. In our experiments on established benchmark datasets we show that our model achieves state-of-the- art performance in both forecasting accuracy and inference time, while using fewer parameters compared to baselines.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Forecasting irregularly sampled multivariate time series with missing values (IMTS) is a fundamental challenge in domains such as healthcare, climate science, and biology.</div>
</details>
</div>
<div class="card">
<div class="title">DP-aware AdaLN-Zero: Taming Conditioning-Induced Heavy-Tailed Gradients in Differentially Private Diffusion</div>
<div class="meta-line">Authors: Tao Huang, Jiayang Meng, Xu Yang, Chen Hou, Hong Chen</div>
<div class="meta-line">First: 2026-02-26T04:32:07+00:00 · Latest: 2026-02-26T04:32:07+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.22610v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.22610v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Condition injection enables diffusion models to generate context-aware outputs, which is essential for many time-series tasks. However, heterogeneous conditional contexts (e.g., observed history, missingness patterns or outlier covariates) can induce heavy-tailed per-example gradients. Under Differentially Private Stochastic Gradient Descent (DP-SGD), these rare conditioning-driven heavy-tailed gradients disproportionately trigger global clipping, resulting in outlier-dominated updates, larger clipping bias, and degraded utility under a fixed privacy budget. In this paper, we propose DP-aware AdaLN-Zero, a drop-in sensitivity-aware conditioning mechanism for conditional diffusion transformers that limits conditioning-induced gain without modifying the DP-SGD mechanism. DP-aware AdaLN-Zero jointly constrains conditioning representation magnitude and AdaLN modulation parameters via bounded re-parameterization, suppressing extreme gradient tail events before gradient clipping and noise injection. Empirically, DP-SGD equipped with DP-aware AdaLN-Zero improves interpolation/imputation and forecasting under matched privacy settings. We observe consistent gains on a real-world power dataset and two public ETT benchmarks over vanilla DP-SGD. Moreover, gradient diagnostics attribute these improvements to conditioning-specific tail reshaping and reduced clipping distortion, while preserving expressiveness in non-private training. Overall, these results show that sensitivity-aware conditioning can substantially improve private conditional diffusion training without sacrificing standard performance.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Condition injection enables diffusion models to generate context-aware outputs, which is essential for many time-series tasks.</div>
</details>
</div>
<div class="card">
<div class="title">Coarse-to-Fine Learning of Dynamic Causal Structures</div>
<div class="meta-line">Authors: Dezhi Yang, Qiaoyu Tan, Carlotta Domeniconi, Jun Wang, Lizhen Cui, Guoxian Yu</div>
<div class="meta-line">First: 2026-02-26T02:12:34+00:00 · Latest: 2026-02-26T02:12:34+00:00</div>
<div class="meta-line">Comments: Accepted by ICLR2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.22532v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.22532v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Learning the dynamic causal structure of time series is a challenging problem. Most existing approaches rely on distributional or structural invariance to uncover underlying causal dynamics, assuming stationary or partially stationary causality. However, these assumptions often conflict with the complex, time-varying causal relationships observed in real-world systems. This motivates the need for methods that address fully dynamic causality, where both instantaneous and lagged dependencies evolve over time. Such a setting poses significant challenges for the efficiency and stability of causal discovery. To address these challenges, we introduce DyCausal, a dynamic causal structure learning framework. DyCausal leverages convolutional networks to capture causal patterns within coarse-grained time windows, and then applies linear interpolation to refine causal structures at each time step, thereby recovering fine-grained and time-varying causal graphs. In addition, we propose an acyclic constraint based on matrix norm scaling, which improves efficiency while effectively constraining loops in evolving causal structures. Comprehensive evaluations on both synthetic and real-world datasets demonstrate that DyCausal achieves superior performance compared to existing methods, offering a stable and efficient approach for identifying fully dynamic causal structures from coarse to fine.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Learning the dynamic causal structure of time series is a challenging problem.</div>
</details>
</div>
<div class="card">
<div class="title">TEFL: Prediction-Residual-Guided Rolling Forecasting for Multi-Horizon Time Series</div>
<div class="meta-line">Authors: Xiannan Huang, Shen Fang, Shuhan Qiu, Chengcheng Yu, Jiayuan Du, Chao Yang</div>
<div class="meta-line">First: 2026-02-26T01:31:58+00:00 · Latest: 2026-02-26T01:31:58+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.22520v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.22520v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Time series forecasting plays a critical role in domains such as transportation, energy, and meteorology. Despite their success, modern deep forecasting models are typically trained to minimize point-wise prediction loss without leveraging the rich information contained in past prediction residuals from rolling forecasts - residuals that reflect persistent biases, unmodeled patterns, or evolving dynamics. We propose TEFL (Temporal Error Feedback Learning), a unified learning framework that explicitly incorporates these historical residuals into the forecasting pipeline during both training and evaluation. To make this practical in deep multi-step settings, we address three key challenges: (1) selecting observable multi-step residuals under the partial observability of rolling forecasts, (2) integrating them through a lightweight low-rank adapter to preserve efficiency and prevent overfitting, and (3) designing a two-stage training procedure that jointly optimizes the base forecaster and error module. Extensive experiments across 10 real-world datasets and 5 backbone architectures show that TEFL consistently improves accuracy, reducing MAE by 5-10% on average. Moreover, it demonstrates strong robustness under abrupt changes and distribution shifts, with error reductions exceeding 10% (up to 19.5%) in challenging scenarios. By embedding residual-based feedback directly into the learning process, TEFL offers a simple, general, and effective enhancement to modern deep forecasting systems.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Time series forecasting plays a critical role in domains such as transportation, energy, and meteorology.</div>
</details>
</div>
<div class="card">
<div class="title">TokEye: Fast Signal Extraction for Fluctuating Time Series via Offline Self-Supervised Learning From Fusion Diagnostics to Bioacoustics</div>
<div class="meta-line">Authors: Nathaniel Chen, Kouroche Bouchiat, Peter Steiner, Andrew Rothstein, David Smith, Max Austin, Mike van Zeeland, Azarakhsh Jalalvand, Egemen Kolemen</div>
<div class="meta-line">First: 2026-02-23T20:03:10+00:00 · Latest: 2026-02-26T01:13:38+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.20317v2">Abs</a> · <a href="https://arxiv.org/pdf/2602.20317v2">PDF</a> · <a href="https://github.com/PlasmaControl/TokEye">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Next-generation fusion facilities like ITER face a &quot;data deluge,&quot; generating petabytes of multi-diagnostic signals daily that challenge manual analysis. We present a &quot;signals-first&quot; self-supervised framework for the automated extraction of coherent and transient modes from high-noise time-frequency data across a variety of sensors. We also develop a general-purpose method and tool for extracting coherent, quasi-coherent, and transient modes for fluctuation measurements in tokamaks by employing non-linear optimal techniques in multichannel signal processing with a fast neural network surrogate on fast magnetics, electron cyclotron emission, CO2 interferometers, and beam emission spectroscopy measurements from DIII-D. Results are tested on data from DIII-D, TJ-II, and non-fusion spectrograms. With an inference latency of 0.5 seconds, this framework enables real-time mode identification and large-scale automated database generation for advanced plasma control. Repository is in https://github.com/PlasmaControl/TokEye.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Next-generation fusion facilities like ITER face a &quot;data deluge,&quot; generating petabytes of multi-diagnostic signals daily that challenge manual analysis.</div>
</details>
</div>
<div class="card">
<div class="title">Online time series prediction using feature adjustment</div>
<div class="meta-line">Authors: Xiannan Huang, Shuhan Qiu, Jiayuan Du, Chao Yang</div>
<div class="meta-line">Venue: ICLR 2026</div>
<div class="meta-line">First: 2025-09-04T01:54:48+00:00 · Latest: 2026-02-26T01:06:30+00:00</div>
<div class="meta-line">Comments: Camera ready version for ICLR 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2509.03810v2">Abs</a> · <a href="https://arxiv.org/pdf/2509.03810v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Time series forecasting is of significant importance across various domains. However, it faces significant challenges due to distribution shift. This issue becomes particularly pronounced in online deployment scenarios where data arrives sequentially, requiring models to adapt continually to evolving patterns. Current time series online learning methods focus on two main aspects: selecting suitable parameters to update (e.g., final layer weights or adapter modules) and devising suitable update strategies (e.g., using recent batches, replay buffers, or averaged gradients). We challenge the conventional parameter selection approach, proposing that distribution shifts stem from changes in underlying latent factors influencing the data. Consequently, updating the feature representations of these latent factors may be more effective. To address the critical problem of delayed feedback in multi-step forecasting (where true values arrive much later than predictions), we introduce ADAPT-Z (Automatic Delta Adjustment via Persistent Tracking in Z-space). ADAPT-Z utilizes an adapter module that leverages current feature representations combined with historical gradient information to enable robust parameter updates despite the delay. Extensive experiments demonstrate that our method consistently outperforms standard base models without adaptation and surpasses state-of-the-art online learning approaches across multiple datasets.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Time series forecasting is of significant importance across various domains.</div>
</details>
</div>
<div class="card">
<div class="title">TimeBlind: A Spatio-Temporal Compositionality Benchmark for Video LLMs</div>
<div class="meta-line">Authors: Baiqi Li, Kangyi Zhao, Ce Zhang, Chancharik Mitra, Jean de Dieu Nyandwi, Gedas Bertasius</div>
<div class="meta-line">First: 2026-01-30T20:21:46+00:00 · Latest: 2026-02-25T18:57:52+00:00</div>
<div class="meta-line">Comments: For code and data, see https://baiqi-li.github.io/timeblind_project/</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.00288v3">Abs</a> · <a href="https://arxiv.org/pdf/2602.00288v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a> · <a href="https://baiqi-li.github.io/timeblind_project/">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Fine-grained spatio-temporal understanding is essential for video reasoning and embodied AI. Yet, while Multimodal Large Language Models (MLLMs) master static semantics, their grasp of temporal dynamics remains brittle. We present TimeBlind, a diagnostic benchmark for compositional spatio-temporal understanding. Inspired by cognitive science, TimeBlind categorizes fine-grained temporal understanding into three levels: recognizing atomic events, characterizing event properties, and reasoning about event interdependencies. Unlike benchmarks that conflate recognition with temporal reasoning, TimeBlind leverages a minimal-pairs paradigm: video pairs share identical static visual content but differ solely in temporal structure, utilizing complementary questions to neutralize language priors. Evaluating over 20 state-of-the-art MLLMs (e.g., GPT-5, Gemini 3 Pro) on 600 curated instances (2400 video-question pairs), reveals that the Instance Accuracy (correctly distinguishing both videos in a pair) of the best performing MLLM is only 48.2%, far below the human performance (98.2%). These results demonstrate that even frontier models rely heavily on static visual shortcuts rather than genuine temporal logic, positioning TimeBlind as a vital diagnostic tool for next-generation video understanding. Dataset and code are available at https://baiqi-li.github.io/timeblind_project/ .</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Fine-grained spatio-temporal understanding is essential for video reasoning and embodied AI.</div>
</details>
</div>
<div class="card">
<div class="title">Training-Free Generative Modeling via Kernelized Stochastic Interpolants</div>
<div class="meta-line">Authors: Florentin Coeurdoux, Etienne Lempereur, Nathanaël Cuvelle-Magar, Thomas Eboli, Stéphane Mallat, Anastasia Borovykh, Eric Vanden-Eijnden</div>
<div class="meta-line">First: 2026-02-23T17:26:09+00:00 · Latest: 2026-02-25T16:39:12+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.20070v2">Abs</a> · <a href="https://arxiv.org/pdf/2602.20070v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We develop a kernel method for generative modeling within the stochastic interpolant framework, replacing neural network training with linear systems. The drift of the generative SDE is $\hat b_t(x) = \nablaφ(x)^\topη_t$, where $η_t\in\R^P$ solves a $P\times P$ system computable from data, with $P$ independent of the data dimension $d$. Since estimates are inexact, the diffusion coefficient $D_t$ affects sample quality; the optimal $D_t^*$ from Girsanov diverges at $t=0$, but this poses no difficulty and we develop an integrator that handles it seamlessly. The framework accommodates diverse feature maps -- scattering transforms, pretrained generative models etc. -- enabling training-free generation and model combination. We demonstrate the approach on financial time series, turbulence, and image generation.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">We develop a kernel method for generative modeling within the stochastic interpolant framework, replacing neural network training with linear systems.</div>
</details>
</div>
<div class="card">
<div class="title">DualWeaver: Synergistic Feature Weaving Surrogates for Multivariate Forecasting with Univariate Time Series Foundation Models</div>
<div class="meta-line">Authors: Jinpeng Li, Zhongyi Pei, Huaze Xue, Bojian Zheng, Chen Wang, Jianmin Wang</div>
<div class="meta-line">First: 2026-02-25T16:13:12+00:00 · Latest: 2026-02-25T16:13:12+00:00</div>
<div class="meta-line">Comments: 16 pages. Preprint</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.22066v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.22066v1">PDF</a> · <a href="https://github.com/li-jinpeng/DualWeaver">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Time-series foundation models (TSFMs) have achieved strong univariate forecasting through large-scale pre-training, yet effectively extending this success to multivariate forecasting remains challenging. To address this, we propose DualWeaver, a novel framework that adapts univariate TSFMs (Uni-TSFMs) for multivariate forecasting by using a pair of learnable, structurally symmetric surrogate series. Generated by a shared auxiliary feature-fusion module that captures cross-variable dependencies, these surrogates are mapped to TSFM-compatible series via the forecasting objective. The symmetric structure enables parameter-free reconstruction of final predictions directly from the surrogates, without additional parametric decoding. A theoretically grounded regularization term is further introduced to enhance robustness against adaptation collapse. Extensive experiments on diverse real-world datasets show that DualWeaver outperforms state-of-the-art multivariate forecasters in both accuracy and stability. We release the code at https://github.com/li-jinpeng/DualWeaver.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Time-series foundation models (TSFMs) have achieved strong univariate forecasting through large-scale pre-training, yet effectively extending this success to multivariate forecasting remains challenging.</div>
</details>
</div>
<div class="card">
<div class="title">Modular Deep Learning for Multivariate Time-Series: Decoupling Imputation and Downstream Tasks</div>
<div class="meta-line">Authors: Joseph Arul Raj, Linglong Qian, Zina Ibrahim</div>
<div class="meta-line">First: 2024-11-06T14:18:23+00:00 · Latest: 2026-02-25T15:50:07+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2411.03941v3">Abs</a> · <a href="https://arxiv.org/pdf/2411.03941v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Missing values are pervasive in large-scale time-series data, posing challenges for reliable analysis and decision-making. Many neural architectures have been designed to model and impute the complex and heterogeneous missingness patterns of such data. Most existing methods are end-to-end, rendering imputation tightly coupled with downstream predictive tasks and leading to limited reusability of the trained model, reduced interpretability, and challenges in assessing model quality. In this paper, we call for a modular approach that decouples imputation and downstream tasks, enabling independent optimisation and greater adaptability. Using the largest open-source Python library for deep learning-based time-series analysis, PyPOTS, we evaluate a modular pipeline across six state-of-the-art models that perform imputation and prediction on seven datasets spanning multiple domains. Our results show that a modular approach maintains high performance while prioritising flexibility and reusability - qualities that are crucial for real-world applications. Through this work, we aim to demonstrate how modularity can benefit multivariate time-series analysis, achieving a balance between performance and adaptability.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Missing values are pervasive in large-scale time-series data, posing challenges for reliable analysis and decision-making.</div>
</details>
</div>
<div class="card">
<div class="title">Rethinking Evaluation in the Era of Time Series Foundation Models: (Un)known Information Leakage Challenges</div>
<div class="meta-line">Authors: Marcel Meyer, Sascha Kaltenpoth, Kevin Zalipski, Oliver Müller</div>
<div class="meta-line">First: 2025-10-15T15:15:45+00:00 · Latest: 2026-02-25T14:48:58+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2510.13654v3">Abs</a> · <a href="https://arxiv.org/pdf/2510.13654v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Time Series Foundation Models (TSFMs) represent a new paradigm for time-series forecasting, promising zero-shot predictions without the need for task-specific training or fine-tuning. However, similar to Large Language Models (LLMs), the evaluation of TSFMs is challenging: as training corpora grow increasingly large, it becomes difficult to ensure the integrity of the test sets used for benchmarking. An investigation of existing TSFM evaluation studies identifies two kinds of information leakage: (1) train-test sample overlaps arising from the multi-purpose reuse of datasets and (2) temporal overlap of correlated train and test series. Ignoring these forms of information leakage when benchmarking TSFMs risks producing overly optimistic performance estimates that fail to generalize to real-world settings. We therefore argue for the development of novel evaluation methodologies that avoid pitfalls already observed in both LLM and classical time-series benchmarking, and we call on the research community to adopt principled approaches to safeguard the integrity of TSFM evaluation.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Time Series Foundation Models (TSFMs) represent a new paradigm for time-series forecasting, promising zero-shot predictions without the need for task-specific training or fine-tuning.</div>
</details>
</div>
<div class="card">
<div class="title">Learning Unknown Interdependencies for Decentralized Root Cause Analysis in Nonlinear Dynamical Systems</div>
<div class="meta-line">Authors: Ayush Mohanty, Paritosh Ramanan, Nagi Gebraeel</div>
<div class="meta-line">First: 2026-02-25T14:05:38+00:00 · Latest: 2026-02-25T14:05:38+00:00</div>
<div class="meta-line">Comments: Manuscript under review</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.21928v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.21928v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Root cause analysis (RCA) in networked industrial systems, such as supply chains and power networks, is notoriously difficult due to unknown and dynamically evolving interdependencies among geographically distributed clients. These clients represent heterogeneous physical processes and industrial assets equipped with sensors that generate large volumes of nonlinear, high-dimensional, and heterogeneous IoT data. Classical RCA methods require partial or full knowledge of the system&#x27;s dependency graph, which is rarely available in these complex networks. While federated learning (FL) offers a natural framework for decentralized settings, most existing FL methods assume homogeneous feature spaces and retrainable client models. These assumptions are not compatible with our problem setting. Different clients have different data features and often run fixed, proprietary models that cannot be modified. This paper presents a federated cross-client interdependency learning methodology for feature-partitioned, nonlinear time-series data, without requiring access to raw sensor streams or modifying proprietary client models. Each proprietary local client model is augmented with a Machine Learning (ML) model that encodes cross-client interdependencies. These ML models are coordinated via a global server that enforces representation consistency while preserving privacy through calibrated differential privacy noise. RCA is performed using model residuals and anomaly flags. We establish theoretical convergence guarantees and validate our approach on extensive simulations and a real-world industrial cybersecurity dataset.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Root cause analysis (RCA) in networked industrial systems, such as supply chains and power networks, is notoriously difficult due to unknown and dynamically evolving interdependencies among geographically distributed clients.</div>
</details>
</div>
<div class="card">
<div class="title">Enhancing Spatio-Temporal Forecasting with Spatial Neighbourhood Fusion:A Case Study on COVID-19 Mobility in Peru</div>
<div class="meta-line">Authors: Chuan Li, Jiang You, Hassine Moungla, Vincent Gauthier, Miguel Nunez-del-Prado, Hugo Alatrista-Salas</div>
<div class="meta-line">First: 2025-06-17T23:51:36+00:00 · Latest: 2026-02-25T13:15:53+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2507.00031v2">Abs</a> · <a href="https://arxiv.org/pdf/2507.00031v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Accurate modeling of human mobility is critical for understanding epidemic spread and deploying timely interventions. In this work, we leverage a large-scale spatio-temporal dataset collected from Peru&#x27;s national Digital Contact Tracing (DCT) application during the COVID-19 pandemic to forecast mobility flows across urban regions. A key challenge lies in the spatial sparsity of hourly mobility counts across hexagonal grid cells, which limits the predictive power of conventional time series models. To address this, we propose a lightweight and model-agnostic Spatial Neighbourhood Fusion (SPN) technique that augments each cell&#x27;s features with aggregated signals from its immediate H3 neighbors. We evaluate this strategy on three forecasting backbones: NLinear, PatchTST, and K-U-Net, under various historical input lengths. Experimental results show that SPN consistently improves forecasting performance, achieving up to 9.85 percent reduction in test MSE. Our findings demonstrate that spatial smoothing of sparse mobility signals provides a simple yet effective path toward robust spatio-temporal forecasting during public health crises.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Accurate modeling of human mobility is critical for understanding epidemic spread and deploying timely interventions.</div>
</details>
</div>
<div class="card">
<div class="title">When Fusion Helps and When It Breaks: View-Aligned Robustness in Same-Source Financial Imaging</div>
<div class="meta-line">Authors: Rui Ma</div>
<div class="meta-line">First: 2026-02-11T16:45:23+00:00 · Latest: 2026-02-25T11:45:18+00:00</div>
<div class="meta-line">Comments: Added sensitivity analysis at tau=0.008 for adversarial robustness; corrected the author affiliation</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.11020v2">Abs</a> · <a href="https://arxiv.org/pdf/2602.11020v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We study same-source multi-view learning and adversarial robustness for next-day direction prediction using two deterministic, window-aligned image views derived from the same time series: an OHLCV-rendered chart (ohlcv) and a technical-indicator matrix (indic). To control label ambiguity from near-zero moves, we use an ex-post minimum-movement threshold min_move (tau) based on realized absolute next-day return, defining an offline benchmark on the subset where the absolute next-day return is at least tau. Under leakage-resistant time-block splits with embargo, we compare early fusion (channel stacking) and dual-encoder late fusion with optional cross-branch consistency. We then evaluate pixel-space L-infinity evasion attacks (FGSM/PGD) under view-constrained and joint threat models. We find that fusion is regime dependent: early fusion can suffer negative transfer under noisier settings, whereas late fusion is a more reliable default once labels stabilize. Robustness degrades sharply under tiny budgets with stable view-dependent vulnerabilities; late fusion often helps under view-constrained attacks, but joint perturbations remain challenging.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">We study same-source multi-view learning and adversarial robustness for next-day direction prediction using two deterministic, window-aligned image views derived from the same time series: an OHLCV-rendered chart (ohlcv) and a technical-indicator matrix (indic).</div>
</details>
</div>
<div class="card">
<div class="title">RAMSeS: Robust and Adaptive Model Selection for Time-Series Anomaly Detection Algorithms</div>
<div class="meta-line">Authors: Mohamed Abdelmaksoud, Sheng Ding, Andrey Morozov, Ziawasch Abedjan</div>
<div class="meta-line">First: 2026-02-25T10:36:32+00:00 · Latest: 2026-02-25T10:36:32+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.21766v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.21766v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Time-series data vary widely across domains, making a universal anomaly detector impractical. Methods that perform well on one dataset often fail to transfer because what counts as an anomaly is context dependent. The key challenge is to design a method that performs well in specific contexts while remaining adaptable across domains with varying data complexities. We present the Robust and Adaptive Model Selection for Time-Series Anomaly Detection RAMSeS framework. RAMSeS comprises two branches: (i) a stacking ensemble optimized with a genetic algorithm to leverage complementary detectors. (ii) An adaptive model-selection branch identifies the best single detector using techniques including Thompson sampling, robustness testing with generative adversarial networks, and Monte Carlo simulations. This dual strategy exploits the collective strength of multiple models and adapts to dataset-specific characteristics. We evaluate RAMSeS and show that it outperforms prior methods on F1.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Time-series data vary widely across domains, making a universal anomaly detector impractical.</div>
</details>
</div>
<div class="card">
<div class="title">Positional-aware Spatio-Temporal Network for Large-Scale Traffic Prediction</div>
<div class="meta-line">Authors: Runfei Chen</div>
<div class="meta-line">First: 2026-02-25T09:39:17+00:00 · Latest: 2026-02-25T09:39:17+00:00</div>
<div class="meta-line">Comments: Accepted for the 104th Transportation Research Board (TRB) Annual Meeting in 2025</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.22274v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.22274v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Traffic flow forecasting has emerged as an indispensable mission for daily life, which is required to utilize the spatiotemporal relationship between each location within a time period under a graph structure to predict future flow. However, the large travel demand for broader geographical areas and longer time spans requires models to distinguish each node clearly and possess a holistic view of the history, which has been paid less attention to in prior works. Furthermore, increasing sizes of data hinder the deployment of most models in real application environments. To this end, in this paper, we propose a lightweight Positional-aware Spatio-Temporal Network (PASTN) to effectively capture both temporal and spatial complexities in an end-to-end manner. PASTN introduces positional-aware embeddings to separate each node&#x27;s representation, while also utilizing a temporal attention module to improve the long-range perception of current models. Extensive experiments verify the effectiveness and efficiency of PASTN across datasets of various scales (county, megalopolis and state). Further analysis demonstrates the efficacy of newly introduced modules either.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Traffic flow forecasting has emerged as an indispensable mission for daily life, which is required to utilize the spatiotemporal relationship between each location within a time period under a graph structure to predict future flow.</div>
</details>
</div>
<div class="card">
<div class="title">TiMi: Empower Time Series Transformers with Multimodal Mixture of Experts</div>
<div class="meta-line">Authors: Jiafeng Lin, Yuxuan Wang, Huakun Luo, Zhongyi Pei, Jianmin Wang</div>
<div class="meta-line">First: 2026-02-25T08:51:03+00:00 · Latest: 2026-02-25T08:51:03+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.21693v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.21693v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Multimodal time series forecasting has garnered significant attention for its potential to provide more accurate predictions than traditional single-modality models by leveraging rich information inherent in other modalities. However, due to fundamental challenges in modality alignment, existing methods often struggle to effectively incorporate multimodal data into predictions, particularly textual information that has a causal influence on time series fluctuations, such as emergency reports and policy announcements. In this paper, we reflect on the role of textual information in numerical forecasting and propose Time series transformers with Multimodal Mixture-of-Experts, TiMi, to unleash the causal reasoning capabilities of LLMs. Concretely, TiMi utilizes LLMs to generate inferences on future developments, which serve as guidance for time series forecasting. To seamlessly integrate both exogenous factors and time series into predictions, we introduce a Multimodal Mixture-of-Experts (MMoE) module as a lightweight plug-in to empower Transformer-based time series models for multimodal forecasting, eliminating the need for explicit representation-level alignment. Experimentally, our proposed TiMi demonstrates consistent state-of-the-art performance on sixteen real-world multimodal forecasting benchmarks, outperforming advanced baselines while offering both strong adaptability and interpretability.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Multimodal time series forecasting has garnered significant attention for its potential to provide more accurate predictions than traditional single-modality models by leveraging rich information inherent in other modalities.</div>
</details>
</div>
<div class="card">
<div class="title">SciTS: Scientific Time Series Understanding and Generation with LLMs</div>
<div class="meta-line">Authors: Wen Wu, Ziyang Zhang, Liwei Liu, Xuenan Xu, Jimin Zhuang, Ke Fan, Qitan Lv, Junlin Liu, Chen Zhang, Zheqi Yuan, Siyuan Hou, Tianyi Lin, Kai Chen, Bowen Zhou, Chao Zhang</div>
<div class="meta-line">Venue: ICLR 2026</div>
<div class="meta-line">First: 2025-09-26T09:25:16+00:00 · Latest: 2026-02-25T08:50:49+00:00</div>
<div class="meta-line">Comments: Accepted to ICLR 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2510.03255v2">Abs</a> · <a href="https://arxiv.org/pdf/2510.03255v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The scientific reasoning ability of large language models (LLMs) has recently attracted significant attention. Time series, as a fundamental modality in scientific data, presents unique challenges that are often overlooked in current multimodal LLMs, which either encode numerical sequences as text or convert them into images. Such approaches may be insufficient for comprehensive scientific time series understanding and generation. Existing unified time series models typically specialise in either forecasting or analysis, and their effectiveness on non-periodic, heterogeneous scientific signals remains unclear. To address these gaps, we introduce SciTS, a benchmark spanning 12 scientific domains and 43 tasks, with over 50k+ instances, both univariate and multivariate signals ranging from $10^0$ to $10^7$ in length and up to 10~MHz in frequency. We benchmark 17 models, including text-only LLMs, multimodal LLMs, and unified time series models, and find that general-purpose LLMs exhibit stronger generalisability than specialised time series models, while representing time series as text or images limits their performance due to excessively long sequences and loss of numerical precision, respectively. We then introduce TimeOmni, a framework that equips LLMs with the ability to understand and generate time series while remaining compatible with general-purpose LLM training. This work fills a gap in both dedicated benchmarks and modelling frameworks for scientific time series, paving the way for LLMs to understand and generate complex temporal scientific data.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The scientific reasoning ability of large language models (LLMs) has recently attracted significant attention.</div>
</details>
</div>
<div class="card">
<div class="title">Prior Knowledge-enhanced Spatio-temporal Epidemic Forecasting</div>
<div class="meta-line">Authors: Sijie Ruan, Jinyu Li, Jia Wei, Zenghao Xu, Jie Bao, Junshi Xu, Junyang Qiu, Hanning Yuan, Xiaoxiao Wang, Shuliang Wang</div>
<div class="meta-line">First: 2026-02-25T07:52:11+00:00 · Latest: 2026-02-25T07:52:11+00:00</div>
<div class="meta-line">Comments: 12 pages, 10 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.22270v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.22270v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Spatio-temporal epidemic forecasting is critical for public health management, yet existing methods often struggle with insensitivity to weak epidemic signals, over-simplified spatial relations, and unstable parameter estimation. To address these challenges, we propose the Spatio-Temporal priOr-aware Epidemic Predictor (STOEP), a novel hybrid framework that integrates implicit spatio-temporal priors and explicit expert priors. STOEP consists of three key components: (1) Case-aware Adjacency Learning (CAL), which dynamically adjusts mobility-based regional dependencies using historical infection patterns; (2) Space-informed Parameter Estimating (SPE), which employs learnable spatial priors to amplify weak epidemic signals; and (3) Filter-based Mechanistic Forecasting (FMF), which uses an expert-guided adaptive thresholding strategy to regularize epidemic parameters. Extensive experiments on real-world COVID-19 and influenza datasets demonstrate that STOEP outperforms the best baseline by 11.1% in RMSE. The system has been deployed at one provincial CDC in China to facilitate downstream applications.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Spatio-temporal epidemic forecasting is critical for public health management, yet existing methods often struggle with insensitivity to weak epidemic signals, over-simplified spatial relations, and unstable parameter estimation.</div>
</details>
</div>
<div class="card">
<div class="title">A Comprehensive Benchmark for Electrocardiogram Time-Series</div>
<div class="meta-line">Authors: Zhijiang Tang, Jiaxin Qi, Yuhua Zheng, Jianqiang Huang</div>
<div class="meta-line">Venue: ACM MM 2025</div>
<div class="meta-line">First: 2025-07-15T02:54:24+00:00 · Latest: 2026-02-25T07:17:42+00:00</div>
<div class="meta-line">Comments: ACM MM 2025</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2507.14206v2">Abs</a> · <a href="https://arxiv.org/pdf/2507.14206v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Electrocardiogram~(ECG), a key bioelectrical time-series signal, is crucial for assessing cardiac health and diagnosing various diseases. Given its time-series format, ECG data is often incorporated into pre-training datasets for large-scale time-series model training. However, existing studies often overlook its unique characteristics and specialized downstream applications, which differ significantly from other time-series data, leading to an incomplete understanding of its properties. In this paper, we present an in-depth investigation of ECG signals and establish a comprehensive benchmark, which includes (1) categorizing its downstream applications into four distinct evaluation tasks, (2) identifying limitations in traditional evaluation metrics for ECG analysis, and introducing a novel metric; (3) benchmarking state-of-the-art time-series models and proposing a new architecture. Extensive experiments demonstrate that our proposed benchmark is comprehensive and robust. The results validate the effectiveness of the proposed metric and model architecture, which establish a solid foundation for advancing research in ECG signal analysis.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Electrocardiogram~(ECG), a key bioelectrical time-series signal, is crucial for assessing cardiac health and diagnosing various diseases.</div>
</details>
</div>
<div class="card">
<div class="title">Characteristic Root Analysis and Regularization for Linear Time Series Forecasting</div>
<div class="meta-line">Authors: Zheng Wang, Kaixuan Zhang, Wanfang Chen, Xiaonan Lu, Longyuan Li, Tobias Schlagenhauf</div>
<div class="meta-line">First: 2025-09-28T03:06:30+00:00 · Latest: 2026-02-25T05:33:12+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2509.23597v3">Abs</a> · <a href="https://arxiv.org/pdf/2509.23597v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Time series forecasting remains a critical challenge across numerous domains, yet the effectiveness of complex models often varies unpredictably across datasets. Recent studies highlight the surprising competitiveness of simple linear models, suggesting that their robustness and interpretability warrant deeper theoretical investigation. This paper presents a systematic study of linear models for time series forecasting, with a focus on the role of characteristic roots in temporal dynamics. We begin by analyzing the noise-free setting, where we show that characteristic roots govern long-term behavior and explain how design choices such as instance normalization and channel independence affect model capabilities. We then extend our analysis to the noisy regime, revealing that models tend to produce spurious roots. This leads to the identification of a key data-scaling property: mitigating the influence of noise requires disproportionately large training data, highlighting the need for structural regularization. To address these challenges, we propose two complementary strategies for robust root restructuring. The first uses rank reduction techniques, including \textbf{Reduced-Rank Regression (RRR)} and \textbf{Direct Weight Rank Reduction (DWRR)}, to recover the low-dimensional latent dynamics. The second, a novel adaptive method called \textbf{Root Purge}, encourages the model to learn a noise-suppressing null space during training. Extensive experiments on standard benchmarks demonstrate the effectiveness of both approaches, validating our theoretical insights and achieving state-of-the-art results in several settings. Our findings underscore the potential of integrating classical theories for linear systems with modern learning techniques to build robust, interpretable, and data-efficient forecasting models.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Time series forecasting remains a critical challenge across numerous domains, yet the effectiveness of complex models often varies unpredictably across datasets.</div>
</details>
</div>
<div class="card">
<div class="title">Learning Recursive Multi-Scale Representations for Irregular Multivariate Time Series Forecasting</div>
<div class="meta-line">Authors: Boyuan Li, Zhen Liu, Yicheng Luo, Qianli Ma</div>
<div class="meta-line">Venue: ICLR 2026</div>
<div class="meta-line">First: 2026-02-25T02:14:42+00:00 · Latest: 2026-02-25T02:14:42+00:00</div>
<div class="meta-line">Comments: Accepted in ICLR 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.21498v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.21498v1">PDF</a> · <a href="https://github.com/Ladbaby/PyOmniTS">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Irregular Multivariate Time Series (IMTS) are characterized by uneven intervals between consecutive timestamps, which carry sampling pattern information valuable and informative for learning temporal and variable dependencies. In addition, IMTS often exhibit diverse dependencies across multiple time scales. However, many existing multi-scale IMTS methods use resampling to obtain the coarse series, which can alter the original timestamps and disrupt the sampling pattern information. To address the challenge, we propose ReIMTS, a Recursive multi-scale modeling approach for Irregular Multivariate Time Series forecasting. Instead of resampling, ReIMTS keeps timestamps unchanged and recursively splits each sample into subsamples with progressively shorter time periods. Based on the original sampling timestamps in these long-to-short subsamples, an irregularity-aware representation fusion mechanism is proposed to capture global-to-local dependencies for accurate forecasting. Extensive experiments demonstrate an average performance improvement of 27.1\% in the forecasting task across different models and real-world datasets. Our code is available at https://github.com/Ladbaby/PyOmniTS.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Irregular Multivariate Time Series (IMTS) are characterized by uneven intervals between consecutive timestamps, which carry sampling pattern information valuable and informative for learning temporal and variable dependencies.</div>
</details>
</div>
<div class="card">
<div class="title">MoEMba: A Mamba-based Mixture of Experts for High-Density EMG-based Hand Gesture Recognition</div>
<div class="meta-line">Authors: Mehran Shabanpour, Kasra Rad, Sadaf Khademi, Arash Mohammadi</div>
<div class="meta-line">First: 2025-02-09T17:07:46+00:00 · Latest: 2026-02-24T18:08:53+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2502.17457v2">Abs</a> · <a href="https://arxiv.org/pdf/2502.17457v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">High-Density surface Electromyography (HDsEMG) has emerged as a pivotal resource for Human-Computer Interaction (HCI), offering direct insights into muscle activities and motion intentions. However, a significant challenge in practical implementations of HD-sEMG-based models is the low accuracy of inter-session and inter-subject classification. Variability between sessions can reach up to 40% due to the inherent temporal variability of HD-sEMG signals. Targeting this challenge, the paper introduces the MoEMba framework, a novel approach leveraging Selective StateSpace Models (SSMs) to enhance HD-sEMG-based gesture recognition. The MoEMba framework captures temporal dependencies and cross-channel interactions through channel attention techniques. Furthermore, wavelet feature modulation is integrated to capture multi-scale temporal and spatial relations, improving signal representation. Experimental results on the CapgMyo HD-sEMG dataset demonstrate that MoEMba achieves a balanced accuracy of 56.9%, outperforming its state-of-the-art counterparts. The proposed framework&#x27;s robustness to session-to-session variability and its efficient handling of high-dimensional multivariate time series data highlight its potential for advancing HD-sEMG-powered HCI systems.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">High-Density surface Electromyography (HDsEMG) has emerged as a pivotal resource for Human-Computer Interaction (HCI), offering direct insights into muscle activities and motion intentions.</div>
</details>
</div></div>
    <details style="margin-top:16px" class="detail"><summary>History</summary>
      <div class="history-list"><a href="archive/20260227_0343.html">20260227_0343</a>
<a href="archive/20260226_0348.html">20260226_0348</a>
<a href="archive/20260225_0348.html">20260225_0348</a>
<a href="archive/20260224_0355.html">20260224_0355</a>
<a href="archive/20260223_0323.html">20260223_0323</a>
<a href="archive/20260222_0323.html">20260222_0323</a>
<a href="archive/20260221_0336.html">20260221_0336</a>
<a href="archive/20260220_0338.html">20260220_0338</a>
<a href="archive/20260219_0348.html">20260219_0348</a>
<a href="archive/20260218_0346.html">20260218_0346</a>
<a href="archive/20260217_0331.html">20260217_0331</a>
<a href="archive/20260216_0324.html">20260216_0324</a>
<a href="archive/20260215_0322.html">20260215_0322</a>
<a href="archive/20260213_0348.html">20260213_0348</a>
<a href="archive/20260212_0355.html">20260212_0355</a>
<a href="archive/20260211_0358.html">20260211_0358</a>
<a href="archive/20260210_0401.html">20260210_0401</a>
<a href="archive/20260208_0323.html">20260208_0323</a>
<a href="archive/20260207_0337.html">20260207_0337</a>
<a href="archive/20260206_0336.html">20260206_0336</a>
<a href="archive/20260205_0338.html">20260205_0338</a>
<a href="archive/20260204_0344.html">20260204_0344</a>
<a href="archive/20260202_0323.html">20260202_0323</a>
<a href="archive/20260201_0320.html">20260201_0320</a>
<a href="archive/20260131_0331.html">20260131_0331</a>
<a href="archive/20260130_0330.html">20260130_0330</a>
<a href="archive/20260129_0327.html">20260129_0327</a>
<a href="archive/20260127_0323.html">20260127_0323</a>
<a href="archive/20260126_0316.html">20260126_0316</a>
<a href="archive/20260125_0316.html">20260125_0316</a>
<a href="archive/20260124_0323.html">20260124_0323</a>
<a href="archive/20260123_0324.html">20260123_0324</a>
<a href="archive/20260122_0326.html">20260122_0326</a>
<a href="archive/20260121_0411.html">20260121_0411</a>
<a href="archive/20260120_0319.html">20260120_0319</a>
<a href="archive/20260119_0315.html">20260119_0315</a>
<a href="archive/20260118_0315.html">20260118_0315</a>
<a href="archive/20260117_0319.html">20260117_0319</a>
<a href="archive/20260116_0323.html">20260116_0323</a>
<a href="archive/20260115_0318.html">20260115_0318</a>
<a href="archive/20260114_0319.html">20260114_0319</a>
<a href="archive/20260113_0320.html">20260113_0320</a>
<a href="archive/20260112_0315.html">20260112_0315</a>
<a href="archive/20260111_0315.html">20260111_0315</a>
<a href="archive/20260110_0319.html">20260110_0319</a>
<a href="archive/20260109_0319.html">20260109_0319</a>
<a href="archive/20260108_0320.html">20260108_0320</a>
<a href="archive/20260107_0316.html">20260107_0316</a>
<a href="archive/20260106_0320.html">20260106_0320</a>
<a href="archive/20260105_0315.html">20260105_0315</a>
<a href="archive/20260104_2357.html">20260104_2357</a>
<a href="archive/20260104_0328.html">20260104_0328</a>
<a href="archive/20260103_0325.html">20260103_0325</a>
<a href="archive/20260102_0339.html">20260102_0339</a>
<a href="archive/20260101_0329.html">20260101_0329</a>
<a href="archive/20251231_0333.html">20251231_0333</a>
<a href="archive/20251230_0332.html">20251230_0332</a>
<a href="archive/20251229_0329.html">20251229_0329</a>
<a href="archive/20251228_0332.html">20251228_0332</a>
<a href="archive/20251227_0329.html">20251227_0329</a>
<a href="archive/20251226_0330.html">20251226_0330</a>
<a href="archive/20251225_0329.html">20251225_0329</a>
<a href="archive/20251224_0331.html">20251224_0331</a>
<a href="archive/20251223_0332.html">20251223_0332</a>
<a href="archive/20251222_0328.html">20251222_0328</a>
<a href="archive/20251221_0329.html">20251221_0329</a>
<a href="archive/20251220_0330.html">20251220_0330</a>
<a href="archive/20251219_0330.html">20251219_0330</a>
<a href="archive/20251218_0345.html">20251218_0345</a>
<a href="archive/20251217_0332.html">20251217_0332</a>
<a href="archive/20251216_0333.html">20251216_0333</a>
<a href="archive/20251215_0333.html">20251215_0333</a>
<a href="archive/20251214_0327.html">20251214_0327</a>
<a href="archive/20251212_0333.html">20251212_0333</a>
<a href="archive/20251211_0331.html">20251211_0331</a>
<a href="archive/20251210_0332.html">20251210_0332</a>
<a href="archive/20251209_0331.html">20251209_0331</a>
<a href="archive/20251208_0328.html">20251208_0328</a>
<a href="archive/20251207_0327.html">20251207_0327</a>
<a href="archive/20251206_0330.html">20251206_0330</a>
<a href="archive/20251205_0331.html">20251205_0331</a>
<a href="archive/20251204_0331.html">20251204_0331</a>
<a href="archive/20251203_0333.html">20251203_0333</a>
<a href="archive/20251202_0335.html">20251202_0335</a>
<a href="archive/20251201_0328.html">20251201_0328</a>
<a href="archive/20251130_0327.html">20251130_0327</a>
<a href="archive/20251129_0328.html">20251129_0328</a>
<a href="archive/20251128_0327.html">20251128_0327</a>
<a href="archive/20251127_0327.html">20251127_0327</a>
<a href="archive/20251126_0329.html">20251126_0329</a>
<a href="archive/20251125_0327.html">20251125_0327</a>
<a href="archive/20251124_0327.html">20251124_0327</a>
<a href="archive/20251123_0326.html">20251123_0326</a>
<a href="archive/20251122_0328.html">20251122_0328</a>
<a href="archive/20251121_0328.html">20251121_0328</a>
<a href="archive/20251120_0329.html">20251120_0329</a>
<a href="archive/20251119_0328.html">20251119_0328</a>
<a href="archive/20251118_0328.html">20251118_0328</a>
<a href="archive/20251117_0326.html">20251117_0326</a>
<a href="archive/20251116_0325.html">20251116_0325</a>
<a href="archive/20251115_0327.html">20251115_0327</a>
<a href="archive/20251114_0328.html">20251114_0328</a>
<a href="archive/20251113_0330.html">20251113_0330</a>
<a href="archive/20251112_0329.html">20251112_0329</a>
<a href="archive/20251111_0328.html">20251111_0328</a>
<a href="archive/20251110_0325.html">20251110_0325</a>
<a href="archive/20251109_0326.html">20251109_0326</a>
<a href="archive/20251108_0328.html">20251108_0328</a>
<a href="archive/20251107_0328.html">20251107_0328</a>
<a href="archive/20251106_0329.html">20251106_0329</a>
<a href="archive/20251105_0326.html">20251105_0326</a>
<a href="archive/20251104_0327.html">20251104_0327</a>
<a href="archive/20251103_0324.html">20251103_0324</a>
<a href="archive/20251102_0326.html">20251102_0326</a>
<a href="archive/20251101_0324.html">20251101_0324</a>
<a href="archive/20251031_0328.html">20251031_0328</a>
<a href="archive/20251030_0330.html">20251030_0330</a>
<a href="archive/20251029_0329.html">20251029_0329</a>
<a href="archive/20251028_0329.html">20251028_0329</a>
<a href="archive/20251027_0322.html">20251027_0322</a>
<a href="archive/20251026_0327.html">20251026_0327</a>
<a href="archive/20251025_0331.html">20251025_0331</a>
<a href="archive/20251024_0329.html">20251024_0329</a>
<a href="archive/20251023_0329.html">20251023_0329</a>
<a href="archive/20251022_0330.html">20251022_0330</a>
<a href="archive/20251021_0331.html">20251021_0331</a>
<a href="archive/20251020_0328.html">20251020_0328</a>
<a href="archive/20251019_0321.html">20251019_0321</a>
<a href="archive/20251018_0327.html">20251018_0327</a>
<a href="archive/20251017_0320.html">20251017_0320</a>
<a href="archive/20251016_0328.html">20251016_0328</a>
<a href="archive/20251015_0328.html">20251015_0328</a>
<a href="archive/20251014_0323.html">20251014_0323</a>
<a href="archive/20251011_0328.html">20251011_0328</a>
<a href="archive/20251010_0330.html">20251010_0330</a>
<a href="archive/20251009_0321.html">20251009_0321</a>
<a href="archive/20251008_0343.html">20251008_0343</a>
<a href="archive/20251007_0353.html">20251007_0353</a>
<a href="archive/20251006_0325.html">20251006_0325</a>
<a href="archive/20251005_0350.html">20251005_0350</a>
<a href="archive/20251004_0352.html">20251004_0352</a>
<a href="archive/20251003_0352.html">20251003_0352</a>
<a href="archive/20251002_0356.html">20251002_0356</a>
<a href="archive/20251001_0321.html">20251001_0321</a>
<a href="archive/20250925_0335.html">20250925_0335</a>
<a href="archive/20250924_0350.html">20250924_0350</a>
<a href="archive/20250923_0348.html">20250923_0348</a>
<a href="archive/20250922_0346.html">20250922_0346</a>
<a href="archive/20250921_0345.html">20250921_0345</a>
<a href="archive/20250920_0342.html">20250920_0342</a>
<a href="archive/20250919_0346.html">20250919_0346</a>
<a href="archive/20250918_0342.html">20250918_0342</a>
<a href="archive/20250917_0336.html">20250917_0336</a>
<a href="archive/20250916_0333.html">20250916_0333</a>
<a href="archive/20250915_0333.html">20250915_0333</a>
<a href="archive/20250914_0328.html">20250914_0328</a>
<a href="archive/20250913_0322.html">20250913_0322</a>
<a href="archive/20250912_0335.html">20250912_0335</a>
<a href="archive/20250911_0337.html">20250911_0337</a>
<a href="archive/20250910_0338.html">20250910_0338</a>
<a href="archive/20250909_0341.html">20250909_0341</a>
<a href="archive/20250908_0342.html">20250908_0342</a>
<a href="archive/20250907_0333.html">20250907_0333</a>
<a href="archive/20250906_0350.html">20250906_0350</a>
<a href="archive/20250905_0319.html">20250905_0319</a>
<a href="archive/20250904_0323.html">20250904_0323</a>
<a href="archive/20250903_0355.html">20250903_0355</a>
<a href="archive/20250902_0325.html">20250902_0325</a>
<a href="archive/20250901_0355.html">20250901_0355</a>
<a href="archive/20250831_0355.html">20250831_0355</a>
<a href="archive/20250830_0356.html">20250830_0356</a>
<a href="archive/20250829_0355.html">20250829_0355</a>
<a href="archive/20250828_0333.html">20250828_0333</a>
<a href="archive/20250827_1654.html">20250827_1654</a>
<a href="archive/20250827_1602.html">20250827_1602</a>
<a href="archive/20250827_1557.html">20250827_1557</a>
<a href="archive/20250827_0320.html">20250827_0320</a>
<a href="archive/20250826_0320.html">20250826_0320</a>
<a href="archive/20250825_1752.html">20250825_1752</a>
<a href="archive/20250825_1709.html">20250825_1709</a>
<a href="archive/20250825_1652.html">20250825_1652</a>
<a href="archive/20250825_1647.html">20250825_1647</a>
<a href="archive/20250825_1645.html">20250825_1645</a>
<a href="archive/20250825_1631.html">20250825_1631</a>
<a href="archive/20250825_1606.html">20250825_1606</a>
<a href="archive/20250825_1559.html">20250825_1559</a>
<a href="archive/20250825_1558.html">20250825_1558</a>
<a href="archive/20250825_1556.html">20250825_1556</a>
<a href="archive/20250825_1531.html">20250825_1531</a>
<a href="archive/20250825_1525.html">20250825_1525</a>
<a href="archive/20250825_1516.html">20250825_1516</a>
<a href="archive/20250825_1450.html">20250825_1450</a>
<a href="archive/20250825_1444.html">20250825_1444</a>
<a href="archive/20250825_1438.html">20250825_1438</a>
<a href="archive/20250825_1414.html">20250825_1414</a>
<a href="archive/20250825_1413.html">20250825_1413</a>
<a href="archive/20250825_1410.html">20250825_1410</a>
<a href="archive/20250825_1408.html">20250825_1408</a>
<a href="archive/20250825_1405.html">20250825_1405</a>
<a href="archive/20250825_1401.html">20250825_1401</a>
<a href="archive/20250825_1355.html">20250825_1355</a>
<a href="archive/20250825_1347.html">20250825_1347</a>
<a href="archive/20250825_1345.html">20250825_1345</a>
<a href="archive/20250825_1344.html">20250825_1344</a>
<a href="archive/20250825_1343.html">20250825_1343</a>
<a href="archive/20250825_1340.html">20250825_1340</a>
<a href="archive/20250825_1339.html">20250825_1339</a>
<a href="archive/20250825_1333.html">20250825_1333</a>
<a href="archive/20250825_1323.html">20250825_1323</a>
<a href="archive/20250825_1317.html">20250825_1317</a>
<a href="archive/20250825_1243.html">20250825_1243</a>
<a href="archive/20250824_0342.html">20250824_0342</a>
<a href="archive/20250823_0343.html">20250823_0343</a>
<a href="archive/20250823_0142.html">20250823_0142</a>
<a href="archive/20250822_2331.html">20250822_2331</a>
<a href="archive/20250822_2308.html">20250822_2308</a>
<a href="archive/20250822_2258.html">20250822_2258</a>
<a href="archive/20250822_2241.html">20250822_2241</a>
<a href="archive/20250822_2228.html">20250822_2228</a>
<a href="archive/20250822_2206.html">20250822_2206</a>
<a href="archive/20250822_2147.html">20250822_2147</a>
<a href="archive/20250822_2111.html">20250822_2111</a>
<a href="archive/20250822_1259.html">20250822_1259</a>
<a href="archive/20250822_1233.html">20250822_1233</a>
<a href="archive/20250822_1229.html">20250822_1229</a>
<a href="archive/20250822_1223.html">20250822_1223</a>
<a href="archive/20250822_1210.html">20250822_1210</a>
<a href="archive/20250822_1201.html">20250822_1201</a>
<a href="archive/20250822_1111.html">20250822_1111</a>
<a href="archive/20250822_1058.html">20250822_1058</a>
<a href="archive/20250822_1052.html">20250822_1052</a>
<a href="archive/20250822_1045.html">20250822_1045</a>
<a href="archive/20250822_0657.html">20250822_0657</a>
<a href="archive/20250822_0553.html">20250822_0553</a></div>
    </details>
    <div class="footer">Generated by arxiv-tracker</div>
  </div>
</body></html>
