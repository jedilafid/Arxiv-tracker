<!doctype html>
<html><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1">
<title>arXiv 论文速递</title><style>
:root {
  --bg:#f8fafc; --card:#ffffff; --text:#0f172a; --muted:#667085; --border:#e5e7eb; --acc:#2563eb;
}
:root[data-theme="dark"] {
  --bg:#0b0f17; --card:#111827; --text:#e5e7eb; --muted:#9ca3af; --border:#1f2937; --acc:#2563eb;
}
*{box-sizing:border-box} body{margin:0;background:var(--bg);color:var(--text);
  font-family:ui-sans-serif,system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial;line-height:1.6;}
.container{max-width:900px;margin:0 auto;padding:18px;}
.header{display:flex;gap:10px;justify-content:space-between;align-items:center;margin:8px 0 16px;flex-wrap:wrap}
h1{font-size:22px;margin:0}
.badge{font-size:12px;color:#111827;background:var(--acc);padding:2px 8px;border-radius:999px}
.card{background:var(--card);border:1px solid var(--border);border-radius:16px;padding:16px 18px;margin:14px 0;box-shadow:0 1px 2px rgba(0,0,0,.04)}
.title{font-weight:700;margin:0 0 6px 0;font-size:18px}
.meta-line{color:var(--muted);font-size:13px;margin:2px 0}
.links a{color:var(--acc);text-decoration:none;margin-right:12px}
.detail{margin-top:10px;background:rgba(2,6,23,.03);border:1px solid var(--border);border-radius:10px;padding:8px 10px}
summary{cursor:pointer;color:var(--acc)}
.mono{white-space:pre-wrap;background:rgba(2,6,23,.03);border:1px solid var(--border);padding:10px;border-radius:10px}
.row{display:grid;grid-template-columns:1fr;gap:12px}
@media (min-width: 860px) {
  .row-2{grid-template-columns:1fr 1fr}
}
.footer{color:var(--muted);font-size:13px;margin:20px 0 10px}
.hr{height:1px;background:var(--border);margin:14px 0}
.history-list a{display:block;color:var(--acc);text-decoration:none;margin:4px 0}
.controls{display:flex;gap:8px;align-items:center}
.btn{border:1px solid var(--border);background:var(--card);padding:6px 10px;border-radius:10px;cursor:pointer;color:var(--text)}
.btn:hover{border-color:var(--acc)}
</style>
<script>
(function() {
  const root = document.documentElement;
  function apply(t) {
    if (t==='dark') root.setAttribute('data-theme','dark');
    else if (t==='light') root.removeAttribute('data-theme');
    else {
      if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches)
        root.setAttribute('data-theme','dark');
      else root.removeAttribute('data-theme');
    }
  }
  let t = localStorage.getItem('theme') || 'light';
  if (!['light','dark','auto'].includes(t)) t='light';
  apply(t);
  window.__toggleTheme = function() {
    let cur = localStorage.getItem('theme') || 'light';
    if (cur==='light') cur='dark';
    else if (cur==='dark') cur='auto';
    else cur='light';
    localStorage.setItem('theme', cur);
    apply(cur);
    const el=document.getElementById('theme-label');
    if(el) el.textContent = cur.toUpperCase();
  }
  window.__expandAll = function(open) {
    document.querySelectorAll('details').forEach(d => d.open = !!open);
  }
})();
</script>
</head>
<body>
  <div class="container">
    <div class="header">
      <h1>arXiv 论文速递</h1>
      <div style="display:flex;gap:10px;align-items:center">
        
<div class="controls">
  <button class="btn" onclick="__toggleTheme()">Theme: <span id="theme-label" style="margin-left:6px">AUTO</span></button>
  <button class="btn" onclick="__expandAll(true)">Expand All</button>
  <button class="btn" onclick="__expandAll(false)">Collapse All</button>
</div>

        <span class="badge">2026-02-24 03:55</span>
      </div>
    </div>
    <div class="hr"></div>
    <div>Snapshot: 20260224_0355</div>
    <div class="row"><div class="card">
<div class="title">Theory and interpretability of Quantum Extreme Learning Machines: a Pauli-transfer matrix approach</div>
<div class="meta-line">Authors: Markus Gross, Hans-Martin Rieser</div>
<div class="meta-line">First: 2026-02-20T17:33:27+00:00 · Latest: 2026-02-20T17:33:27+00:00</div>
<div class="meta-line">Comments: 34 pages, 12 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.18377v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.18377v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Quantum reservoir computers (QRCs) have emerged as a promising approach to quantum machine learning, since they utilize the natural dynamics of quantum systems for data processing and are simple to train. Here, we consider n-qubit quantum extreme learning machines (QELMs) with continuous-time reservoir dynamics. QELMs are memoryless QRCs capable of various ML tasks, including image classification and time series forecasting. We apply the Pauli transfer matrix (PTM) formalism to theoretically analyze the influence of encoding, reservoir dynamics, and measurement operations, including temporal multiplexing, on the QELM performance. This formalism makes explicit that the encoding determines the complete set of (nonlinear) features available to the QELM, while the quantum channels linearly transform these features before they are probed by the chosen measurement operators. Optimizing a QELM can therefore be cast as a decoding problem in which one shapes the channel-induced transformations such that task-relevant features become available to the regressor. The PTM formalism allows one to identify the classical representation of a QELM and thereby guide its design towards a given training objective. As a specific application, we focus on learning nonlinear dynamical systems and show that a QELM trained on such trajectories learns a surrogate-approximation to the underlying flow map.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Quantum reservoir computers (QRCs) have emerged as a promising approach to quantum machine learning, since they utilize the natural dynamics of quantum systems for data processing and are simple to train.</div>
</details>
</div>
<div class="card">
<div class="title">Analyzing and Improving Chain-of-Thought Monitorability Through Information Theory</div>
<div class="meta-line">Authors: Usman Anwar, Tim Bakker, Dana Kianfar, Cristina Pinneri, Christos Louizos</div>
<div class="meta-line">First: 2026-02-20T15:50:30+00:00 · Latest: 2026-02-20T15:50:30+00:00</div>
<div class="meta-line">Comments: First two authors contributed equally</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.18297v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.18297v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Chain-of-thought (CoT) monitors are LLM-based systems that analyze reasoning traces to detect when outputs may exhibit attributes of interest, such as test-hacking behavior during code generation. In this paper, we use information-theoretic analysis to show that non-zero mutual information between CoT and output is a necessary but not sufficient condition for CoT monitorability. We identify two sources of approximation error that may undermine the performance of CoT monitors in practice: information gap, which measures the extent to which the monitor can extract the information available in CoT, and elicitation error, which measures the extent to which the monitor approximates the optimal monitoring function. We further demonstrate that CoT monitorability can be systematically improved through targeted training objectives. To this end, we propose two complementary approaches: (a) an oracle-based method that directly rewards the monitored model for producing CoTs that maximize monitor accuracy, and (b) a more practical, label-free approach that maximizes conditional mutual information between outputs and CoTs. Across multiple different environments, we show both methods significantly improve monitor accuracy while preventing CoT degeneration even when training against a monitor, thereby mitigating reward hacking when the task reward is imperfectly specified.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Chain-of-thought (CoT) monitors are LLM-based systems that analyze reasoning traces to detect when outputs may exhibit attributes of interest, such as test-hacking behavior during code generation.</div>
</details>
</div>
<div class="card">
<div class="title">A Deep Surrogate Model for Robust and Generalizable Long-Term Blast Wave Prediction</div>
<div class="meta-line">Authors: Danning Jing, Xinhai Chen, Xifeng Pu, Jie Hu, Chao Huang, Xuguang Chen, Qinglin Wang, Jie Liu</div>
<div class="meta-line">First: 2026-02-20T12:14:28+00:00 · Latest: 2026-02-20T12:14:28+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.18168v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.18168v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Accurately modeling the spatio-temporal dynamics of blast wave propagation remains a longstanding challenge due to its highly nonlinear behavior, sharp gradients, and burdensome computational cost. While machine learning-based surrogate models offer fast inference as a promising alternative, they suffer from degraded accuracy, particularly evaluated on complex urban layouts or out-of-distribution scenarios. Moreover, autoregressive prediction strategies in such models are prone to error accumulation over long forecasting horizons, limiting their robustness for extended-time simulations. To address these limitations, we propose RGD-Blast, a robust and generalizable deep surrogate model for high-fidelity, long-term blast wave forecasting. RGD-Blast incorporates a multi-scale module to capture both global flow patterns and local boundary interactions, effectively mitigating error accumulation during autoregressive prediction. We introduce a dynamic-static feature coupling mechanism that fuses time-varying pressure fields with static source and layout features, thereby enhancing out-of-distribution generalization. Experiments demonstrate that RGD-Blast achieves a two-order-of-magnitude speedup over traditional numerical methods while maintaining comparable accuracy. In generalization tests on unseen building layouts, the model achieves an average RMSE below 0.01 and an R2 exceeding 0.89 over 280 consecutive time steps. Additional evaluations under varying blast source locations and explosive charge weights further validate its generalization, substantially advancing the state of the art in long-term blast wave modeling.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Accurately modeling the spatio-temporal dynamics of blast wave propagation remains a longstanding challenge due to its highly nonlinear behavior, sharp gradients, and burdensome computational cost.</div>
</details>
</div>
<div class="card">
<div class="title">Ensemble-based graph representation of fMRI data for cognitive brain state classification</div>
<div class="meta-line">Authors: Daniil Vlasenko, Vadim Ushakov, Alexey Zaikin, Denis Zakharov</div>
<div class="meta-line">First: 2025-08-08T08:32:46+00:00 · Latest: 2026-02-20T10:51:43+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2508.06118v2">Abs</a> · <a href="https://arxiv.org/pdf/2508.06118v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">fMRI is a non-invasive technique for investigating brain activity, offering high-resolution insights into neural processes. Understanding and decoding cognitive brain states from fMRI depends on how functional interactions are represented. We propose an ensemble-based graph representation in which each edge weight encodes state evidence as the difference between posterior probabilities of two states, estimated by an ensemble of edge-wise probabilistic classifiers from simple pairwise time-series features. We evaluate the method on seven task-fMRI paradigms from the Human Connectome Project, performing binary classification within each paradigm. Using compact node summaries (mean incident edge weights) and logistic regression, we obtain average accuracies of 97.07-99.74 %. We further compare ensemble graphs with conventional correlation graphs using the same graph neural network classifier; ensemble graphs consistently yield higher accuracy (88.00-99.42 % vs 61.86-97.94 % across tasks). Because edge weights have a probabilistic, state-oriented interpretation, the representation supports connection- and region-level interpretability and can be extended to multiclass decoding, regression, other neuroimaging modalities, and clinical classification.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">fMRI is a non-invasive technique for investigating brain activity, offering high-resolution insights into neural processes.</div>
</details>
</div>
<div class="card">
<div class="title">Learning Long-Range Dependencies with Temporal Predictive Coding</div>
<div class="meta-line">Authors: Tom Potter, Oliver Rhodes</div>
<div class="meta-line">First: 2026-02-20T10:46:28+00:00 · Latest: 2026-02-20T10:46:28+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.18131v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.18131v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Predictive Coding (PC) is a biologically-inspired learning framework characterised by local, parallelisable operations, properties that enable energy-efficient implementation on neuromorphic hardware. Despite this, extending PC effectively to recurrent neural networks (RNNs) has been challenging, particularly for tasks involving long-range temporal dependencies. Backpropagation Through Time (BPTT) remains the dominant method for training RNNs, but its non-local computation, lack of spatial parallelism, and requirement to store extensive activation histories results in significant energy consumption. This work introduces a novel method combining Temporal Predictive Coding (tPC) with approximate Real-Time Recurrent Learning (RTRL), enabling effective spatio-temporal credit assignment. Results indicate that the proposed method can closely match the performance of BPTT on both synthetic benchmarks and real-world tasks. On a challenging machine translation task, with a 15-million parameter model, the proposed method achieves a test perplexity of 7.62 (vs. 7.49 for BPTT), marking one of the first applications of tPC to tasks of this scale. These findings demonstrate the potential of this method to learn complex temporal dependencies whilst retaining the local, parallelisable, and flexible properties of the original PC framework, paving the way for more energy-efficient learning systems.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Predictive Coding (PC) is a biologically-inspired learning framework characterised by local, parallelisable operations, properties that enable energy-efficient implementation on neuromorphic hardware.</div>
</details>
</div>
<div class="card">
<div class="title">Data-Driven Spectral Analysis Through Pseudo-Resolvent Koopman Operator in Dynamical Systems</div>
<div class="meta-line">Authors: Yuanchao Xu, Itsushi Sakata, Isao Ishikawa</div>
<div class="meta-line">First: 2025-12-31T16:33:01+00:00 · Latest: 2026-02-20T01:48:59+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.24953v2">Abs</a> · <a href="https://arxiv.org/pdf/2512.24953v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We present a data-driven method for spectral analysis of the Koopman operator based on direct construction of the pseudo-resolvent from time-series data. Finite-dimensional approximation of the Koopman operator, such as those obtained from Extended Dynamic Mode Decomposition, are known to suffer from spectral pollution. To address this issue, we construct the pseudo-resolvent operator using the Sherman-Morrison-Woodbury identity whose norm serves as a spectral indicator, and pseudoeigenfunctions are extracted as directions of maximal amplification. We establish convergence of the approximate spectrum to the true spectrum in the Hausdorff metric for isolated eigenvalues, with preservation of algebraic multiplicities, and derive error bounds for eigenvalue approximation. Numerical experiments on pendulum, Lorenz, and coupled oscillator systems demonstrate that the method effectively suppresses spectral pollution and resolves closely spaced spectral components.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">We present a data-driven method for spectral analysis of the Koopman operator based on direct construction of the pseudo-resolvent from time-series data.</div>
</details>
</div>
<div class="card">
<div class="title">MantisV2: Closing the Zero-Shot Gap in Time Series Classification with Synthetic Data and Test-Time Strategies</div>
<div class="meta-line">Authors: Vasilii Feofanov, Songkang Wen, Jianfeng Zhang, Lujia Pan, Ievgen Redko</div>
<div class="meta-line">First: 2026-02-19T22:04:23+00:00 · Latest: 2026-02-19T22:04:23+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.17868v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.17868v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Developing foundation models for time series classification is of high practical relevance, as such models can serve as universal feature extractors for diverse downstream tasks. Although early models such as Mantis have shown the promise of this approach, a substantial performance gap remained between frozen and fine-tuned encoders. In this work, we introduce methods that significantly strengthen zero-shot feature extraction for time series. First, we introduce Mantis+, a variant of Mantis pre-trained entirely on synthetic time series. Second, through controlled ablation studies, we refine the architecture and obtain MantisV2, an improved and more lightweight encoder. Third, we propose an enhanced test-time methodology that leverages intermediate-layer representations and refines output-token aggregation. In addition, we show that performance can be further improved via self-ensembling and cross-model embedding fusion. Extensive experiments on UCR, UEA, Human Activity Recognition (HAR) benchmarks, and EEG datasets show that MantisV2 and Mantis+ consistently outperform prior time series foundation models, achieving state-of-the-art zero-shot performance.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Developing foundation models for time series classification is of high practical relevance, as such models can serve as universal feature extractors for diverse downstream tasks.</div>
</details>
</div>
<div class="card">
<div class="title">Financial time series augmentation using transformer based GAN architecture</div>
<div class="meta-line">Authors: Andrzej Podobiński, Jarosław A. Chudziak</div>
<div class="meta-line">First: 2026-02-19T22:02:09+00:00 · Latest: 2026-02-19T22:02:09+00:00</div>
<div class="meta-line">Comments: This paper has been accepted for the upcoming 18th International Conference on Agents and Artificial Intelligence (ICAART-2026), Marbella, Spain. The final published version will appear in the official conference proceedings</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.17865v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.17865v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Time-series forecasting is a critical task across many domains, from engineering to economics, where accurate predictions drive strategic decisions. However, applying advanced deep learning models in challenging, volatile domains like finance is difficult due to the inherent limitation and dynamic nature of financial time series data. This scarcity often results in sub-optimal model training and poor generalization. The fundamental challenge lies in determining how to reliably augment scarce financial time series data to enhance the predictive accuracy of deep learning forecasting models. Our main contribution is a demonstration of how Generative Adversarial Networks (GANs) can effectively serve as a data augmentation tool to overcome data scarcity in the financial domain. Specifically, we show that training a Long Short-Term Memory (LSTM) forecasting model on a dataset augmented with synthetic data generated by a transformer-based GAN (TTS-GAN) significantly improves the forecasting accuracy compared to using real data alone. We confirm these results across different financial time series (Bitcoin and S\&amp;P500 price data) and various forecasting horizons. Furthermore, we propose a novel, time series specific quality metric that combines Dynamic Time Warping (DTW) and a modified Deep Dataset Dissimilarity Measure (DeD-iMs) to reliably monitor the training progress and evaluate the quality of the generated data. These findings provide compelling evidence for the benefits of GAN-based data augmentation in enhancing financial predictive capabilities.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Time-series forecasting is a critical task across many domains, from engineering to economics, where accurate predictions drive strategic decisions.</div>
</details>
</div>
<div class="card">
<div class="title">Individualized and Interpretable Sleep Forecasting via a Two-Stage Adaptive Spatial-Temporal Model</div>
<div class="meta-line">Authors: Xueyi Wang, Claudine J. C. Lamoth, Elisabeth Wilhelm</div>
<div class="meta-line">First: 2025-08-28T19:01:40+00:00 · Latest: 2026-02-19T21:09:50+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2509.06974v2">Abs</a> · <a href="https://arxiv.org/pdf/2509.06974v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Sleep quality impacts well-being. Therefore, healthcare providers and individuals need accessible and reliable forecasting tools for preventive interventions. This paper introduces an interpretable, individualized adaptive spatial-temporal model for predicting sleep quality. We designed a hierarchical architecture, consisting of parallel 1D convolutions with varying kernel sizes and dilated convolution, which extracts multi-resolution temporal patterns-short kernels capture rapid physiological changes, while larger kernels and dilation model slower trends. The extracted features are then refined through channel attention, which learns to emphasize the most predictive variables for each individual, followed by bidirectional LSTM and self-attention that jointly model both local sequential dynamics and global temporal dependencies. Finally, a two-stage adaptation strategy ensures the learned representations transfer effectively to new users. We conducted various experiments with five input window sizes (3, 5, 7, 9, and 11 days) and five prediction window sizes (1, 3, 5, 7, and 9 days). Our model consistently outperformed time series forecasting baseline approaches, including LSTM, Informer, PatchTST, and TimesNet. The best performance was achieved with a three-day input window and a one-day prediction window, yielding an RMSE of 0.216. Furthermore, the model demonstrated good predictive performance even for longer forecasting horizons (e.g., with a 0.257 RMSE for a three-day prediction window), highlighting its practical utility for real-world applications. We also conducted an explainability analysis to examine how different features influence sleep quality. These findings proved that the proposed framework offers a robust, adaptive, and explainable solution for personalized sleep forecasting using sparse data from commercial wearable devices.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Sleep quality impacts well-being.</div>
</details>
</div>
<div class="card">
<div class="title">Causality by Abstraction: Symbolic Rule Learning in Multivariate Timeseries with Large Language Models</div>
<div class="meta-line">Authors: Preetom Biswas, Giulia Pedrielli, K. Selçuk Candan</div>
<div class="meta-line">First: 2026-02-19T20:49:06+00:00 · Latest: 2026-02-19T20:49:06+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.17829v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.17829v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Inferring causal relations in timeseries data with delayed effects is a fundamental challenge, especially when the underlying system exhibits complex dynamics that cannot be captured by simple functional mappings. Traditional approaches often fail to produce generalized and interpretable explanations, as multiple distinct input trajectories may yield nearly indistinguishable outputs. In this work, we present ruleXplain, a framework that leverages Large Language Models (LLMs) to extract formal explanations for input-output relations in simulation-driven dynamical systems. Our method introduces a constrained symbolic rule language with temporal operators and delay semantics, enabling LLMs to generate verifiable causal rules through structured prompting. ruleXplain relies on the availability of a principled model (e.g., a simulator) that maps multivariate input time series to output time series. Within ruleXplain, the simulator is used to generate diverse counterfactual input trajectories that yield similar target output, serving as candidate explanations. Such counterfactual inputs are clustered and provided as context to the LLM, which is tasked with the generation of symbolic rules encoding the joint temporal trends responsible for the patterns observable in the output times series. A closed-loop refinement process ensures rule consistency and semantic validity. We validate the framework using the PySIRTEM epidemic simulator, mapping testing rate inputs to daily infection counts; and the EnergyPlus building energy simulator, observing temperature and solar irradiance inputs to electricity needs. For validation, we perform three classes of experiments: (1) the efficacy of the ruleset through input reconstruction; (2) ablation studies evaluating the causal encoding of the ruleset; and (3) generalization tests of the extracted rules across unseen output trends with varying phase dynamics.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Inferring causal relations in timeseries data with delayed effects is a fundamental challenge, especially when the underlying system exhibits complex dynamics that cannot be captured by simple functional mappings.</div>
</details>
</div>
<div class="card">
<div class="title">TimeBlind: A Spatio-Temporal Compositionality Benchmark for Video LLMs</div>
<div class="meta-line">Authors: Baiqi Li, Kangyi Zhao, Ce Zhang, Chancharik Mitra, Jean de Dieu Nyandwi, Gedas Bertasius</div>
<div class="meta-line">First: 2026-01-30T20:21:46+00:00 · Latest: 2026-02-19T19:49:20+00:00</div>
<div class="meta-line">Comments: For code and data, see https://baiqi-li.github.io/timeblind_project/</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.00288v2">Abs</a> · <a href="https://arxiv.org/pdf/2602.00288v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a> · <a href="https://baiqi-li.github.io/timeblind_project/">Project1</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Fine-grained spatio-temporal understanding is essential for video reasoning and embodied AI. Yet, while Multimodal Large Language Models (MLLMs) master static semantics, their grasp of temporal dynamics remains brittle. We present TimeBlind, a diagnostic benchmark for compositional spatio-temporal understanding. Inspired by cognitive science, TimeBlind categorizes fine-grained temporal understanding into three levels: recognizing atomic events, characterizing event properties, and reasoning about event interdependencies. Unlike benchmarks that conflate recognition with temporal reasoning, TimeBlind leverages a minimal-pairs paradigm: video pairs share identical static visual content but differ solely in temporal structure, utilizing complementary questions to neutralize language priors. Evaluating over 20 state-of-the-art MLLMs (e.g., GPT-5, Gemini 3 Pro) on 600 curated instances (2400 video-question pairs), reveals that the Instance Accuracy (correctly distinguishing both videos in a pair) of the best performing MLLM is only 48.2%, far below the human performance (98.2%). These results demonstrate that even frontier models rely heavily on static visual shortcuts rather than genuine temporal logic, positioning TimeBlind as a vital diagnostic tool for next-generation video understanding. Dataset and code are available at https://baiqi-li.github.io/timeblind_project/ .</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Fine-grained spatio-temporal understanding is essential for video reasoning and embodied AI.</div>
</details>
</div>
<div class="card">
<div class="title">Reverso: Efficient Time Series Foundation Models for Zero-shot Forecasting</div>
<div class="meta-line">Authors: Xinghong Fu, Yanhong Li, Georgios Papaioannou, Yoon Kim</div>
<div class="meta-line">First: 2026-02-19T18:48:08+00:00 · Latest: 2026-02-19T18:48:08+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.17634v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.17634v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Learning time series foundation models has been shown to be a promising approach for zero-shot time series forecasting across diverse time series domains. Insofar as scaling has been a critical driver of performance of foundation models in other modalities such as language and vision, much recent work on time series foundation modeling has focused on scaling. This has resulted in time series foundation models with hundreds of millions of parameters that are, while performant, inefficient and expensive to use in practice. This paper describes a simple recipe for learning efficient foundation models for zero-shot time series forecasting that are orders of magnitude smaller. We show that large-scale transformers are not necessary: small hybrid models that interleave long convolution and linear RNN layers (in particular DeltaNet layers) can match the performance of larger transformer-based models while being more than a hundred times smaller. We also describe several data augmentation and inference strategies that further improve performance. This recipe results in Reverso, a family of efficient time series foundation models for zero-shot forecasting that significantly push the performance-efficiency Pareto frontier.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Learning time series foundation models has been shown to be a promising approach for zero-shot time series forecasting across diverse time series domains.</div>
</details>
</div>
<div class="card">
<div class="title">Be Wary of Your Time Series Preprocessing</div>
<div class="meta-line">Authors: Sofiane Ennadir, Tianze Wang, Oleg Smirnov, Sahar Asadi, Lele Cao</div>
<div class="meta-line">Venue: AAAI</div>
<div class="meta-line">First: 2026-02-19T17:23:56+00:00 · Latest: 2026-02-19T17:23:56+00:00</div>
<div class="meta-line">Comments: Accepted at the AI4TS workshop at AAAI-26</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.17568v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.17568v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Normalization and scaling are fundamental preprocessing steps in time series modeling, yet their role in Transformer-based models remains underexplored from a theoretical perspective. In this work, we present the first formal analysis of how different normalization strategies, specifically instance-based and global scaling, impact the expressivity of Transformer-based architectures for time series representation learning. We propose a novel expressivity framework tailored to time series, which quantifies a model&#x27;s ability to distinguish between similar and dissimilar inputs in the representation space. Using this framework, we derive theoretical bounds for two widely used normalization methods: Standard and Min-Max scaling. Our analysis reveals that the choice of normalization strategy can significantly influence the model&#x27;s representational capacity, depending on the task and data characteristics. We complement our theory with empirical validation on classification and forecasting benchmarks using multiple Transformer-based models. Our results show that no single normalization method consistently outperforms others, and in some cases, omitting normalization entirely leads to superior performance. These findings highlight the critical role of preprocessing in time series learning and motivate the need for more principled normalization strategies tailored to specific tasks and datasets.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Normalization and scaling are fundamental preprocessing steps in time series modeling, yet their role in Transformer-based models remains underexplored from a theoretical perspective.</div>
</details>
</div>
<div class="card">
<div class="title">Time-Varyingness in Auction Breaks Revenue Equivalence</div>
<div class="meta-line">Authors: Yuma Fujimoto, Kaito Ariu, Kenshi Abe</div>
<div class="meta-line">First: 2024-10-16T07:18:25+00:00 · Latest: 2026-02-19T14:39:36+00:00</div>
<div class="meta-line">Comments: 8 pages, 4 figures (main); 6 pages, 1 figure (appendix)</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2410.12306v2">Abs</a> · <a href="https://arxiv.org/pdf/2410.12306v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Auction is applied for trade with various mechanisms. A simple but practical question is which mechanism, typically first-price or second-price auctions, is preferred from the perspective of bidders or sellers. A celebrated answer is revenue equivalence, where each bidder&#x27;s equilibrium payoff is proven to be independent of auction mechanisms (and a seller&#x27;s revenue, too). In reality, however, auction environments like the value distribution of items would vary over time, and such equilibrium bidding cannot always be achieved. Indeed, bidders must continue to track their equilibrium bidding by learning in first-price auctions, but they can keep their equilibrium bidding in second-price auctions. This study discusses whether and how revenue equivalence is violated in the long run by comparing the time series of non-equilibrium bidding in first-price auctions with those of equilibrium bidding in second-price auctions. We characterize the value distribution by two parameters: its basis value, which means the lowest price to bid, and its value interval, which means the width of possible values. Surprisingly, our theorems and experiments find that revenue equivalence is broken by the correlation between the basis value and the value interval, uncovering a novel phenomenon that could occur in the real world.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Auction is applied for trade with various mechanisms.</div>
</details>
</div>
<div class="card">
<div class="title">HPMixer: Hierarchical Patching for Multivariate Time Series Forecasting</div>
<div class="meta-line">Authors: Jung Min Choi, Vijaya Krishna Yalavarthi, Lars Schmidt-Thieme</div>
<div class="meta-line">First: 2026-02-18T13:59:04+00:00 · Latest: 2026-02-19T12:57:13+00:00</div>
<div class="meta-line">Comments: 18 pages, 5 figures, 5 tables, PAKDD 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.16468v2">Abs</a> · <a href="https://arxiv.org/pdf/2602.16468v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">In long-term multivariate time series forecasting, effectively capturing both periodic patterns and residual dynamics is essential. To address this within standard deep learning benchmark settings, we propose the Hierarchical Patching Mixer (HPMixer), which models periodicity and residuals in a decoupled yet complementary manner. The periodic component utilizes a learnable cycle module [7] enhanced with a nonlinear channel-wise MLP for greater expressiveness. The residual component is processed through a Learnable Stationary Wavelet Transform (LSWT) to extract stable, shift-invariant frequency-domain representations. Subsequently, a channel-mixing encoder models explicit inter-channel dependencies, while a two-level non-overlapping hierarchical patching mechanism captures coarse- and fine-scale residual variations. By integrating decoupled periodicity modeling with structured, multi-scale residual learning, HPMixer provides an effective framework. Extensive experiments on standard multivariate benchmarks demonstrate that HPMixer achieves competitive or state-of-the-art performance compared to recent baselines.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">In long-term multivariate time series forecasting, effectively capturing both periodic patterns and residual dynamics is essential.</div>
</details>
</div>
<div class="card">
<div class="title">MGD: Moment Guided Diffusion for Maximum Entropy Generation</div>
<div class="meta-line">Authors: Etienne Lempereur, Nathanaël Cuvelle--Magar, Florentin Coeurdoux, Stéphane Mallat, Eric Vanden-Eijnden</div>
<div class="meta-line">First: 2026-02-19T10:03:03+00:00 · Latest: 2026-02-19T10:03:03+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.17211v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.17211v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Generating samples from limited information is a fundamental problem across scientific domains. Classical maximum entropy methods provide principled uncertainty quantification from moment constraints but require sampling via MCMC or Langevin dynamics, which typically exhibit exponential slowdown in high dimensions. In contrast, generative models based on diffusion and flow matching efficiently transport noise to data but offer limited theoretical guarantees and can overfit when data is scarce. We introduce Moment Guided Diffusion (MGD), which combines elements of both approaches. Building on the stochastic interpolant framework, MGD samples maximum entropy distributions by solving a stochastic differential equation that guides moments toward prescribed values in finite time, thereby avoiding slow mixing in equilibrium-based methods. We formally obtain, in the large-volatility limit, convergence of MGD to the maximum entropy distribution and derive a tractable estimator of the resulting entropy computed directly from the dynamics. Applications to financial time series, turbulent flows, and cosmological fields using wavelet scattering moments yield estimates of negentropy for high-dimensional multiscale processes.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Generating samples from limited information is a fundamental problem across scientific domains.</div>
</details>
</div>
<div class="card">
<div class="title">Exploring Memory Effects: Sparse Identification in Vector-Borne Diseases</div>
<div class="meta-line">Authors: Dimitri Breda, Muhammad Tanveer, Jianhong Wu, Xue Zhang</div>
<div class="meta-line">First: 2026-01-28T13:26:43+00:00 · Latest: 2026-02-19T10:02:21+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.20591v2">Abs</a> · <a href="https://arxiv.org/pdf/2601.20591v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Predicting the human burden of vector-borne diseases from limited surveillance data remains a major challenge, particularly in the presence of nonlinear transmission dynamics and delayed effects arising from vector ecology and human behavior. We develop a data-driven framework based on an extension of Sparse Identification of Nonlinear Dynamics (SINDy) to systems with distributed memory, enabling discovery of transmission mechanisms directly from time series data. Using severe fever with thrombocytopenia syndrome (SFTS) as a case study, we show that this approach can uncover key features of tick-borne disease dynamics using only human incidence and local temperature data, without imposing predefined assumptions on human case reporting. We further demonstrate that predictive performance is substantially enhanced when the data-driven model is coupled with mechanistic representations of tick-host transmission pathways informed by empirical studies. The framework supports systematic sensitivity analysis of memory kernels and behavioral parameters, identifying those most influential for prediction accuracy. Although the approach prioritizes predictive accuracy over mechanistic transparency, it yields sparse, interpretable integral representations suitable for epidemiological forecasting. This hybrid methodology provides a scalable strategy for forecasting vector-borne disease risk and informing public health decision-making under data limitations.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Predicting the human burden of vector-borne diseases from limited surveillance data remains a major challenge, particularly in the presence of nonlinear transmission dynamics and delayed effects arising from vector ecology and human behavior.</div>
</details>
</div>
<div class="card">
<div class="title">TimeOmni-VL: Unified Models for Time Series Understanding and Generation</div>
<div class="meta-line">Authors: Tong Guan, Sheng Pan, Johan Barthelemy, Zhao Li, Yujun Cai, Cesare Alippi, Ming Jin, Shirui Pan</div>
<div class="meta-line">First: 2026-02-19T07:50:11+00:00 · Latest: 2026-02-19T07:50:11+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.17149v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.17149v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Recent time series modeling faces a sharp divide between numerical generation and semantic understanding, with research showing that generation models often rely on superficial pattern matching, while understanding-oriented models struggle with high-fidelity numerical output. Although unified multimodal models (UMMs) have bridged this gap in vision, their potential for time series remains untapped. We propose TimeOmni-VL, the first vision-centric framework that unifies time series understanding and generation through two key innovations: (1) Fidelity-preserving bidirectional mapping between time series and images (Bi-TSI), which advances Time Series-to-Image (TS2I) and Image-to-Time Series (I2TS) conversions to ensure near-lossless transformations. (2) Understanding-guided generation. We introduce TSUMM-Suite, a novel dataset consists of six understanding tasks rooted in time series analytics that are coupled with two generation tasks. With a calibrated Chain-of-Thought, TimeOmni-VL is the first to leverage time series understanding as an explicit control signal for high-fidelity generation. Experiments confirm that this unified approach significantly improves both semantic understanding and numerical precision, establishing a new frontier for multimodal time series modeling.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Recent time series modeling faces a sharp divide between numerical generation and semantic understanding, with research showing that generation models often rely on superficial pattern matching, while understanding-oriented models struggle with high-fidelity numerical output.</div>
</details>
</div>
<div class="card">
<div class="title">Assessing Ionospheric Scintillation Risk for Direct-to-Cellular Communications using Frequency-Scaled GNSS Observations</div>
<div class="meta-line">Authors: Abdollah Masoud Darya, Muhammad Mubasshir Shaikh</div>
<div class="meta-line">First: 2026-02-19T07:41:27+00:00 · Latest: 2026-02-19T07:41:27+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.17143v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.17143v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">One of the key issues facing Direct-to-Cellular (D2C) satellite communication systems is ionospheric scintillation on the uplink and downlink, which can significantly degrade link quality. This work investigates the spatial and temporal characteristics of amplitude scintillation at D2C frequencies by scaling L-band scintillation observations from Global Navigation Satellite Systems (GNSS) receivers to bands relevant to D2C operation, including the low-band, and 3GPP&#x27;s N255 and N256. These observations are then compared to scaled radio-occultation scintillation observations from the FORMOSAT-7/COSMIC-2 (F7/C2) mission, which can be used in regions that do not possess ground-based scintillation monitoring stations. As a proof of concept, five years of ground-based GNSS scintillation data from Sharjah, United Arab Emirates, together with two years of F7/C2 observations over the same region, corresponding to the ascending phase of Solar Cycle 25, are analyzed. Both space-based and ground-based observations indicate a pronounced diurnal scintillation peak between 20--22 local time, particularly during the equinoxes, with occurrence rates increasing with solar activity. Ground-based observations also reveal a strong azimuth dependence, with most scintillation events occurring on southward satellite links. The scintillation occurrence rate at the low-band is more than twice that observed at N255 and N256, highlighting the increased robustness of higher D2C bands to ionospheric scintillation. These results demonstrate how GNSS scintillation observations can be leveraged to characterize and anticipate scintillation-induced D2C link impairments, which help in D2C system design and the implementation of scintillation mitigation strategies.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">One of the key issues facing Direct-to-Cellular (D2C) satellite communication systems is ionospheric scintillation on the uplink and downlink, which can significantly degrade link quality.</div>
</details>
</div>
<div class="card">
<div class="title">TIFO: Time-Invariant Frequency Operator for Stationarity-Aware Representation Learning in Time Series</div>
<div class="meta-line">Authors: Xihao Piao, Zheng Chen, Lingwei Zhu, Yushun Dong, Yasuko Matsubara, Yasushi Sakurai</div>
<div class="meta-line">First: 2026-02-19T06:46:54+00:00 · Latest: 2026-02-19T06:46:54+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.17122v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.17122v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Nonstationary time series forecasting suffers from the distribution shift issue due to the different distributions that produce the training and test data. Existing methods attempt to alleviate the dependence by, e.g., removing low-order moments from each individual sample. These solutions fail to capture the underlying time-evolving structure across samples and do not model the complex time structure. In this paper, we aim to address the distribution shift in the frequency space by considering all possible time structures. To this end, we propose a Time-Invariant Frequency Operator (TIFO), which learns stationarity-aware weights over the frequency spectrum across the entire dataset. The weight representation highlights stationary frequency components while suppressing non-stationary ones, thereby mitigating the distribution shift issue in time series. To justify our method, we show that the Fourier transform of time series data implicitly induces eigen-decomposition in the frequency space. TIFO is a plug-and-play approach that can be seamlessly integrated into various forecasting models. Experiments demonstrate our method achieves 18 top-1 and 6 top-2 results out of 28 forecasting settings. Notably, it yields 33.3% and 55.3% improvements in average MSE on the ETTm2 dataset. In addition, TIFO reduces computational costs by 60% -70% compared to baseline methods, demonstrating strong scalability across diverse forecasting models.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Nonstationary time series forecasting suffers from the distribution shift issue due to the different distributions that produce the training and test data.</div>
</details>
</div>
<div class="card">
<div class="title">AI/ML based Joint Source and Channel Coding for HARQ-ACK Payload</div>
<div class="meta-line">Authors: Akash Doshi, Pinar Sen, Kirill Ivanov, Wei Yang, June Namgoong, Runxin Wang, Rachel Wang, Taesang Yoo, Jing Jiang, Tingfang Ji</div>
<div class="meta-line">First: 2025-11-25T05:31:26+00:00 · Latest: 2026-02-19T06:11:06+00:00</div>
<div class="meta-line">Comments: 39 pages, 15 figures. Under consideration for publication in Journal of Sel. Areas in Information Theory (received Major Revision). This paper was presented in part at the International Symposium on Topics in Coding, August 2025 in the Session for Coding and AI</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2511.19943v2">Abs</a> · <a href="https://arxiv.org/pdf/2511.19943v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Channel coding from 2G to 5G has assumed the inputs bits at the physical layer to be uniformly distributed. However, hybrid automatic repeat request acknowledgement (HARQ-ACK) bits transmitted in the uplink are inherently non-uniformly distributed. For such sources, significant performance gains could be obtained by employing joint source channel coding, aided by deep learning-based techniques. In this paper, we learn a transformer-based encoder using a novel &quot;free-lunch&quot; training algorithm and propose per-codeword power shaping to exploit the source prior at the encoder whilst being robust to small changes in the HARQ-ACK distribution. Furthermore, any HARQ-ACK decoder has to achieve a low negative acknowledgement (NACK) error rate to avoid radio link failures resulting from multiple NACK errors. We develop an extension of the Neyman-Pearson test to a coded bit system with multiple information bits to achieve Unequal Error Protection of NACK over ACK bits at the decoder. Finally, we apply the proposed encoder and decoder designs to a 5G New Radio (NR) compliant uplink setup under a fading channel, describing the optimal receiver design and a low complexity coherent approximation to it. Our results demonstrate 3-6 dB reduction in the average transmit power required to achieve the target error rates compared to the NR baseline, while also achieving a 2-3 dB reduction in the maximum transmit power, thus providing for significant coverage gains and power savings.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Channel coding from 2G to 5G has assumed the inputs bits at the physical layer to be uniformly distributed.</div>
</details>
</div>
<div class="card">
<div class="title">Deep Reinforcement Learning for Optimal Portfolio Allocation: A Comparative Study with Mean-Variance Optimization</div>
<div class="meta-line">Authors: Srijan Sood, Kassiani Papasotiriou, Marius Vaiciulis, Tucker Balch</div>
<div class="meta-line">First: 2026-02-19T05:47:23+00:00 · Latest: 2026-02-19T05:47:23+00:00</div>
<div class="meta-line">Comments: 9 pages, 6 figures. Published at the FinPlan&#x27;23 Workshop, the 33rd International Conference on Automated Planning and Scheduling (ICAPS 2023)</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.17098v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.17098v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Portfolio Management is the process of overseeing a group of investments, referred to as a portfolio, with the objective of achieving predetermined investment goals. Portfolio optimization is a key component that involves allocating the portfolio assets so as to maximize returns while minimizing risk taken. It is typically carried out by financial professionals who use a combination of quantitative techniques and investment expertise to make decisions about the portfolio allocation.
  Recent applications of Deep Reinforcement Learning (DRL) have shown promising results when used to optimize portfolio allocation by training model-free agents on historical market data. Many of these methods compare their results against basic benchmarks or other state-of-the-art DRL agents but often fail to compare their performance against traditional methods used by financial professionals in practical settings. One of the most commonly used methods for this task is Mean-Variance Portfolio Optimization (MVO), which uses historical time series information to estimate expected asset returns and covariances, which are then used to optimize for an investment objective.
  Our work is a thorough comparison between model-free DRL and MVO for optimal portfolio allocation. We detail the specifics of how to make DRL for portfolio optimization work in practice, also noting the adjustments needed for MVO. Backtest results demonstrate strong performance of the DRL agent across many metrics, including Sharpe ratio, maximum drawdowns, and absolute returns.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Portfolio Management is the process of overseeing a group of investments, referred to as a portfolio, with the objective of achieving predetermined investment goals.</div>
</details>
</div>
<div class="card">
<div class="title">GraFSTNet: Graph-based Frequency SpatioTemporal Network for Cellular Traffic Prediction</div>
<div class="meta-line">Authors: Ziyi Li, Hui Ma, Fei Xing, Chunjiong Zhang, Ming Yan</div>
<div class="meta-line">First: 2026-02-06T16:21:06+00:00 · Latest: 2026-02-19T05:25:16+00:00</div>
<div class="meta-line">Comments: there exists some small errors in the manuscript, and we would like to check and resubmit later</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.13282v2">Abs</a> · <a href="https://arxiv.org/pdf/2602.13282v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">With rapid expansion of cellular networks and the proliferation of mobile devices, cellular traffic data exhibits complex temporal dynamics and spatial correlations, posing challenges to accurate traffic prediction. Previous methods often focus predominantly on temporal modeling or depend on predefined spatial topologies, which limits their ability to jointly model spatio-temporal dependencies and effectively capture periodic patterns in cellular traffic. To address these issues, we propose a cellular traffic prediction framework that integrates spatio-temporal modeling with time-frequency analysis. First, we construct a spatial modeling branch to capture inter-cell dependencies through an attention mechanism, minimizing the reliance on predefined topological structures. Second, we build a time-frequency modeling branch to enhance the representation of periodic patterns. Furthermore, we introduce an adaptive-scale LogCosh loss function, which adjusts the error penalty based on traffic magnitude, preventing large errors from dominating the training process and helping the model maintain relatively stable prediction accuracy across different traffic intensities. Experiments on three open-sourced datasets demonstrate that the proposed method achieves prediction performance superior to state-of-the-art approaches.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">With rapid expansion of cellular networks and the proliferation of mobile devices, cellular traffic data exhibits complex temporal dynamics and spatial correlations, posing challenges to accurate traffic prediction.</div>
</details>
</div>
<div class="card">
<div class="title">Spatio-temporal dual-stage hypergraph MARL for human-centric multimodal corridor traffic signal control</div>
<div class="meta-line">Authors: Xiaocai Zhang, Neema Nassir, Milad Haghani</div>
<div class="meta-line">First: 2026-02-19T04:18:50+00:00 · Latest: 2026-02-19T04:18:50+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.17068v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.17068v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Human-centric traffic signal control in corridor networks must increasingly account for multimodal travelers, particularly high-occupancy public transportation, rather than focusing solely on vehicle-centric performance. This paper proposes STDSH-MARL (Spatio-Temporal Dual-Stage Hypergraph based Multi-Agent Reinforcement Learning), a scalable multi-agent deep reinforcement learning framework that follows a centralized training and decentralized execution paradigm. The proposed method captures spatio-temporal dependencies through a novel dual-stage hypergraph attention mechanism that models interactions across both spatial and temporal hyperedges. In addition, a hybrid discrete action space is introduced to jointly determine the next signal phase configuration and its corresponding green duration, enabling more adaptive signal timing decisions. Experiments conducted on a corridor network under five traffic scenarios demonstrate that STDSH-MARL consistently improves multimodal performance and provides clear benefits for public transportation priority. Compared with state-of-the-art baseline methods, the proposed approach achieves superior overall performance. Further ablation studies confirm the contribution of each component of STDSH-MARL, with temporal hyperedges identified as the most influential factor driving the observed performance gains.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Human-centric traffic signal control in corridor networks must increasingly account for multimodal travelers, particularly high-occupancy public transportation, rather than focusing solely on vehicle-centric performance.</div>
</details>
</div>
<div class="card">
<div class="title">Forecasting Anomaly Precursors via Uncertainty-Aware Time-Series Ensembles</div>
<div class="meta-line">Authors: Hyeongwon Kang, Jinwoo Park, Seunghun Han, Pilsung Kang</div>
<div class="meta-line">First: 2026-02-19T02:48:09+00:00 · Latest: 2026-02-19T02:48:09+00:00</div>
<div class="meta-line">Comments: This manuscript contains 14 pages and 8 figures. It is currently under review at IEEE Transactions on Neural Networks and Learning Systems (TNNLS)</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.17028v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.17028v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Detecting anomalies in time-series data is critical in domains such as industrial operations, finance, and cybersecurity, where early identification of abnormal patterns is essential for ensuring system reliability and enabling preventive maintenance. However, most existing methods are reactive: they detect anomalies only after they occur and lack the capability to provide proactive early warning signals. In this paper, we propose FATE (Forecasting Anomalies with Time-series Ensembles), a novel unsupervised framework for detecting Precursors-of-Anomaly (PoA) by quantifying predictive uncertainty from a diverse ensemble of time-series forecasting models. Unlike prior approaches that rely on reconstruction errors or require ground-truth labels, FATE anticipates future values and leverages ensemble disagreement to signal early signs of potential anomalies without access to target values at inference time. To rigorously evaluate PoA detection, we introduce Precursor Time-series Aware Precision and Recall (PTaPR), a new metric that extends the traditional Time-series Aware Precision and Recall (TaPR) by jointly assessing segment-level accuracy, within-segment coverage, and temporal promptness of early predictions. This enables a more holistic assessment of early warning capabilities that existing metrics overlook. Experiments on five real-world benchmark datasets show that FATE achieves an average improvement of 19.9 percentage points in PTaPR AUC and 20.02 percentage points in early detection F1 score, outperforming baselines while requiring no anomaly labels. These results demonstrate the effectiveness and practicality of FATE for real-time unsupervised early warning in complex time-series environments.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Detecting anomalies in time-series data is critical in domains such as industrial operations, finance, and cybersecurity, where early identification of abnormal patterns is essential for ensuring system reliability and enabling preventive maintenance.</div>
</details>
</div>
<div class="card">
<div class="title">Sonar-TS: Search-Then-Verify Natural Language Querying for Time Series Databases</div>
<div class="meta-line">Authors: Zhao Tan, Yiji Zhao, Shiyu Wang, Chang Xu, Yuxuan Liang, Xiping Liu, Shirui Pan, Ming Jin</div>
<div class="meta-line">First: 2026-02-19T01:51:52+00:00 · Latest: 2026-02-19T01:51:52+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.17001v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.17001v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Natural Language Querying for Time Series Databases (NLQ4TSDB) aims to assist non-expert users retrieve meaningful events, intervals, and summaries from massive temporal records. However, existing Text-to-SQL methods are not designed for continuous morphological intents such as shapes or anomalies, while time series models struggle to handle ultra-long histories. To address these challenges, we propose Sonar-TS, a neuro-symbolic framework that tackles NLQ4TSDB via a Search-Then-Verify pipeline. Analogous to active sonar, it utilizes a feature index to ping candidate windows via SQL, followed by generated Python programs to lock on and verify candidates against raw signals. To enable effective evaluation, we introduce NLQTSBench, the first large-scale benchmark designed for NLQ over TSDB-scale histories. Our experiments highlight the unique challenges within this domain and demonstrate that Sonar-TS effectively navigates complex temporal queries where traditional methods fail. This work presents the first systematic study of NLQ4TSDB, offering a general framework and evaluation standard to facilitate future research.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Natural Language Querying for Time Series Databases (NLQ4TSDB) aims to assist non-expert users retrieve meaningful events, intervals, and summaries from massive temporal records.</div>
</details>
</div>
<div class="card">
<div class="title">Position: Why a Dynamical Systems Perspective is Needed to Advance Time Series Modeling</div>
<div class="meta-line">Authors: Daniel Durstewitz, Christoph Jürgen Hemmer, Florian Hess, Charlotte Ricarda Doll, Lukas Eisenmann</div>
<div class="meta-line">First: 2026-02-18T20:46:50+00:00 · Latest: 2026-02-18T20:46:50+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.16864v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.16864v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Time series (TS) modeling has come a long way from early statistical, mainly linear, approaches to the current trend in TS foundation models. With a lot of hype and industrial demand in this field, it is not always clear how much progress there really is. To advance TS forecasting and analysis to the next level, here we argue that the field needs a dynamical systems (DS) perspective. TS of observations from natural or engineered systems almost always originate from some underlying DS, and arguably access to its governing equations would yield theoretically optimal forecasts. This is the promise of DS reconstruction (DSR), a class of ML/AI approaches that aim to infer surrogate models of the underlying DS from data. But models based on DS principles offer other profound advantages: Beyond short-term forecasts, they enable to predict the long-term statistics of an observed system, which in many practical scenarios may be the more relevant quantities. DS theory furthermore provides domain-independent theoretical insight into mechanisms underlying TS generation, and thereby will inform us, e.g., about upper bounds on performance of any TS model, generalization into unseen regimes as in tipping points, or potential control strategies. After reviewing some of the central concepts, methods, measures, and models in DS theory and DSR, we will discuss how insights from this field can advance TS modeling in crucial ways, enabling better forecasting with much lower computational and memory footprints. We conclude with a number of specific suggestions for translating insights from DSR into TS modeling.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Time series (TS) modeling has come a long way from early statistical, mainly linear, approaches to the current trend in TS foundation models.</div>
</details>
</div>
<div class="card">
<div class="title">A Systematic Evaluation of Sample-Level Tokenization Strategies for MEG Foundation Models</div>
<div class="meta-line">Authors: SungJun Cho, Chetan Gohil, Rukuang Huang, Oiwi Parker Jones, Mark W. Woolrich</div>
<div class="meta-line">First: 2026-02-18T17:21:02+00:00 · Latest: 2026-02-18T17:21:02+00:00</div>
<div class="meta-line">Comments: 15 pages, 10 figures, 1 table</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.16626v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.16626v1">PDF</a> · <a href="https://github.com/OHBA-analysis/Cho2026_Tokenizer">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Recent success in natural language processing has motivated growing interest in large-scale foundation models for neuroimaging data. Such models often require discretization of continuous neural time series data, a process referred to as &#x27;tokenization&#x27;. However, the impact of different tokenization strategies for neural data is currently poorly understood. In this work, we present a systematic evaluation of sample-level tokenization strategies for transformer-based large neuroimaging models (LNMs) applied to magnetoencephalography (MEG) data. We compare learnable and non-learnable tokenizers by examining their signal reconstruction fidelity and their impact on subsequent foundation modeling performance (token prediction, biological plausibility of generated data, preservation of subject-specific information, and performance on downstream tasks). For the learnable tokenizer, we introduce a novel approach based on an autoencoder. Experiments were conducted on three publicly available MEG datasets spanning different acquisition sites, scanners, and experimental paradigms. Our results show that both learnable and non-learnable discretization schemes achieve high reconstruction accuracy and broadly comparable performance across most evaluation criteria, suggesting that simple fixed sample-level tokenization strategies can be used in the development of neural foundation models. The code is available at https://github.com/OHBA-analysis/Cho2026_Tokenizer.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Recent success in natural language processing has motivated growing interest in large-scale foundation models for neuroimaging data.</div>
</details>
</div>
<div class="card">
<div class="title">Still Competitive: Revisiting Recurrent Models for Irregular Time Series Prediction</div>
<div class="meta-line">Authors: Ankitkumar Joshi, Milos Hauskrecht</div>
<div class="meta-line">First: 2025-10-17T19:04:16+00:00 · Latest: 2026-02-18T17:10:14+00:00</div>
<div class="meta-line">Comments: Published in Transactions on Machine Learning Research, 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2510.16161v2">Abs</a> · <a href="https://arxiv.org/pdf/2510.16161v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Modeling irregularly sampled multivariate time series is a persistent challenge in domains like healthcare and sensor networks. While recent works have explored a variety of complex learning architectures to solve the prediction problems for irregularly sampled time series, it remains unclear what the true benefits of some of these architectures are, and whether clever modifications of simpler and more efficient RNN-based algorithms are still competitive, i.e. they are on par with or even superior to these methods. In this work, we propose and study GRUwE: Gated Recurrent Unit with Exponential basis functions, that builds upon RNN-based architectures for observations made at irregular times. GRUwE supports both regression-based and event-based predictions in continuous time. GRUwE works by maintaining a Markov state representation of the time series that updates with the arrival of irregular observations. The Markov state update relies on two reset mechanisms: (i) observation-triggered reset to account for the new observation, and (ii) time-triggered reset that relies on learnable exponential decays, to support the predictions in continuous time. Our empirical evaluations across several real-world benchmarks on next-observation and next-event prediction tasks demonstrate that GRUwE can indeed achieve competitive or superior performance compared to the recent state-of-the-art (SOTA) methods. Thanks to its simplicity, GRUwE offers compelling advantages: it is easy to implement, requires minimal hyper-parameter tuning efforts, and significantly reduces the computational overhead in the online deployment.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Modeling irregularly sampled multivariate time series is a persistent challenge in domains like healthcare and sensor networks.</div>
</details>
</div>
<div class="card">
<div class="title">Channel Dependence, Limited Lookback Windows, and the Simplicity of Datasets: How Biased is Time Series Forecasting?</div>
<div class="meta-line">Authors: Ibram Abdelmalak, Kiran Madhusudhanan, Jungmin Choi, Christian Kloetergens, Vijaya Krishna Yalavarit, Maximilian Stubbemann, Lars Schmidt-Thieme</div>
<div class="meta-line">First: 2025-02-13T13:35:10+00:00 · Latest: 2026-02-18T15:24:58+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2502.09683v3">Abs</a> · <a href="https://arxiv.org/pdf/2502.09683v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">In Long-term Time Series Forecasting (LTSF), the lookback window is a critical hyperparameter often set arbitrarily, undermining the validity of model evaluations. We argue that the lookback window must be tuned on a per-task basis to ensure fair comparisons. Our empirical results show that failing to do so can invert performance rankings, particularly when comparing univariate and multivariate methods. Experiments on standard benchmarks reposition Channel-Independent (CI) models, such as PatchTST, as state-of-the-art methods. However, we reveal this superior performance is largely an artifact of weak inter-channel correlations and simplicity of patterns within these specific datasets. Using Granger causality analysis and ODE datasets (with implicit channel correlations), we demonstrate that the true strength of multivariate Channel-Dependent (CD) models emerges on datasets with strong, inherent cross-channel dependencies, where they significantly outperform CI models. We conclude with four key recommendations for improving TSF research: (i) consider the lookback window as a key hyperparameter to tune, (ii) for standard datasets, examining CI architectures is advantageous, (iii) leverage statistical analysis of datasets to guide the choice between CI and CD architectures, and (iv) prefer CD models in scenarios with limited data.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">In Long-term Time Series Forecasting (LTSF), the lookback window is a critical hyperparameter often set arbitrarily, undermining the validity of model evaluations.</div>
</details>
</div></div>
    <details style="margin-top:16px" class="detail"><summary>History</summary>
      <div class="history-list"><a href="archive/20260223_0323.html">20260223_0323</a>
<a href="archive/20260222_0323.html">20260222_0323</a>
<a href="archive/20260221_0336.html">20260221_0336</a>
<a href="archive/20260220_0338.html">20260220_0338</a>
<a href="archive/20260219_0348.html">20260219_0348</a>
<a href="archive/20260218_0346.html">20260218_0346</a>
<a href="archive/20260217_0331.html">20260217_0331</a>
<a href="archive/20260216_0324.html">20260216_0324</a>
<a href="archive/20260215_0322.html">20260215_0322</a>
<a href="archive/20260213_0348.html">20260213_0348</a>
<a href="archive/20260212_0355.html">20260212_0355</a>
<a href="archive/20260211_0358.html">20260211_0358</a>
<a href="archive/20260210_0401.html">20260210_0401</a>
<a href="archive/20260208_0323.html">20260208_0323</a>
<a href="archive/20260207_0337.html">20260207_0337</a>
<a href="archive/20260206_0336.html">20260206_0336</a>
<a href="archive/20260205_0338.html">20260205_0338</a>
<a href="archive/20260204_0344.html">20260204_0344</a>
<a href="archive/20260202_0323.html">20260202_0323</a>
<a href="archive/20260201_0320.html">20260201_0320</a>
<a href="archive/20260131_0331.html">20260131_0331</a>
<a href="archive/20260130_0330.html">20260130_0330</a>
<a href="archive/20260129_0327.html">20260129_0327</a>
<a href="archive/20260127_0323.html">20260127_0323</a>
<a href="archive/20260126_0316.html">20260126_0316</a>
<a href="archive/20260125_0316.html">20260125_0316</a>
<a href="archive/20260124_0323.html">20260124_0323</a>
<a href="archive/20260123_0324.html">20260123_0324</a>
<a href="archive/20260122_0326.html">20260122_0326</a>
<a href="archive/20260121_0411.html">20260121_0411</a>
<a href="archive/20260120_0319.html">20260120_0319</a>
<a href="archive/20260119_0315.html">20260119_0315</a>
<a href="archive/20260118_0315.html">20260118_0315</a>
<a href="archive/20260117_0319.html">20260117_0319</a>
<a href="archive/20260116_0323.html">20260116_0323</a>
<a href="archive/20260115_0318.html">20260115_0318</a>
<a href="archive/20260114_0319.html">20260114_0319</a>
<a href="archive/20260113_0320.html">20260113_0320</a>
<a href="archive/20260112_0315.html">20260112_0315</a>
<a href="archive/20260111_0315.html">20260111_0315</a>
<a href="archive/20260110_0319.html">20260110_0319</a>
<a href="archive/20260109_0319.html">20260109_0319</a>
<a href="archive/20260108_0320.html">20260108_0320</a>
<a href="archive/20260107_0316.html">20260107_0316</a>
<a href="archive/20260106_0320.html">20260106_0320</a>
<a href="archive/20260105_0315.html">20260105_0315</a>
<a href="archive/20260104_2357.html">20260104_2357</a>
<a href="archive/20260104_0328.html">20260104_0328</a>
<a href="archive/20260103_0325.html">20260103_0325</a>
<a href="archive/20260102_0339.html">20260102_0339</a>
<a href="archive/20260101_0329.html">20260101_0329</a>
<a href="archive/20251231_0333.html">20251231_0333</a>
<a href="archive/20251230_0332.html">20251230_0332</a>
<a href="archive/20251229_0329.html">20251229_0329</a>
<a href="archive/20251228_0332.html">20251228_0332</a>
<a href="archive/20251227_0329.html">20251227_0329</a>
<a href="archive/20251226_0330.html">20251226_0330</a>
<a href="archive/20251225_0329.html">20251225_0329</a>
<a href="archive/20251224_0331.html">20251224_0331</a>
<a href="archive/20251223_0332.html">20251223_0332</a>
<a href="archive/20251222_0328.html">20251222_0328</a>
<a href="archive/20251221_0329.html">20251221_0329</a>
<a href="archive/20251220_0330.html">20251220_0330</a>
<a href="archive/20251219_0330.html">20251219_0330</a>
<a href="archive/20251218_0345.html">20251218_0345</a>
<a href="archive/20251217_0332.html">20251217_0332</a>
<a href="archive/20251216_0333.html">20251216_0333</a>
<a href="archive/20251215_0333.html">20251215_0333</a>
<a href="archive/20251214_0327.html">20251214_0327</a>
<a href="archive/20251212_0333.html">20251212_0333</a>
<a href="archive/20251211_0331.html">20251211_0331</a>
<a href="archive/20251210_0332.html">20251210_0332</a>
<a href="archive/20251209_0331.html">20251209_0331</a>
<a href="archive/20251208_0328.html">20251208_0328</a>
<a href="archive/20251207_0327.html">20251207_0327</a>
<a href="archive/20251206_0330.html">20251206_0330</a>
<a href="archive/20251205_0331.html">20251205_0331</a>
<a href="archive/20251204_0331.html">20251204_0331</a>
<a href="archive/20251203_0333.html">20251203_0333</a>
<a href="archive/20251202_0335.html">20251202_0335</a>
<a href="archive/20251201_0328.html">20251201_0328</a>
<a href="archive/20251130_0327.html">20251130_0327</a>
<a href="archive/20251129_0328.html">20251129_0328</a>
<a href="archive/20251128_0327.html">20251128_0327</a>
<a href="archive/20251127_0327.html">20251127_0327</a>
<a href="archive/20251126_0329.html">20251126_0329</a>
<a href="archive/20251125_0327.html">20251125_0327</a>
<a href="archive/20251124_0327.html">20251124_0327</a>
<a href="archive/20251123_0326.html">20251123_0326</a>
<a href="archive/20251122_0328.html">20251122_0328</a>
<a href="archive/20251121_0328.html">20251121_0328</a>
<a href="archive/20251120_0329.html">20251120_0329</a>
<a href="archive/20251119_0328.html">20251119_0328</a>
<a href="archive/20251118_0328.html">20251118_0328</a>
<a href="archive/20251117_0326.html">20251117_0326</a>
<a href="archive/20251116_0325.html">20251116_0325</a>
<a href="archive/20251115_0327.html">20251115_0327</a>
<a href="archive/20251114_0328.html">20251114_0328</a>
<a href="archive/20251113_0330.html">20251113_0330</a>
<a href="archive/20251112_0329.html">20251112_0329</a>
<a href="archive/20251111_0328.html">20251111_0328</a>
<a href="archive/20251110_0325.html">20251110_0325</a>
<a href="archive/20251109_0326.html">20251109_0326</a>
<a href="archive/20251108_0328.html">20251108_0328</a>
<a href="archive/20251107_0328.html">20251107_0328</a>
<a href="archive/20251106_0329.html">20251106_0329</a>
<a href="archive/20251105_0326.html">20251105_0326</a>
<a href="archive/20251104_0327.html">20251104_0327</a>
<a href="archive/20251103_0324.html">20251103_0324</a>
<a href="archive/20251102_0326.html">20251102_0326</a>
<a href="archive/20251101_0324.html">20251101_0324</a>
<a href="archive/20251031_0328.html">20251031_0328</a>
<a href="archive/20251030_0330.html">20251030_0330</a>
<a href="archive/20251029_0329.html">20251029_0329</a>
<a href="archive/20251028_0329.html">20251028_0329</a>
<a href="archive/20251027_0322.html">20251027_0322</a>
<a href="archive/20251026_0327.html">20251026_0327</a>
<a href="archive/20251025_0331.html">20251025_0331</a>
<a href="archive/20251024_0329.html">20251024_0329</a>
<a href="archive/20251023_0329.html">20251023_0329</a>
<a href="archive/20251022_0330.html">20251022_0330</a>
<a href="archive/20251021_0331.html">20251021_0331</a>
<a href="archive/20251020_0328.html">20251020_0328</a>
<a href="archive/20251019_0321.html">20251019_0321</a>
<a href="archive/20251018_0327.html">20251018_0327</a>
<a href="archive/20251017_0320.html">20251017_0320</a>
<a href="archive/20251016_0328.html">20251016_0328</a>
<a href="archive/20251015_0328.html">20251015_0328</a>
<a href="archive/20251014_0323.html">20251014_0323</a>
<a href="archive/20251011_0328.html">20251011_0328</a>
<a href="archive/20251010_0330.html">20251010_0330</a>
<a href="archive/20251009_0321.html">20251009_0321</a>
<a href="archive/20251008_0343.html">20251008_0343</a>
<a href="archive/20251007_0353.html">20251007_0353</a>
<a href="archive/20251006_0325.html">20251006_0325</a>
<a href="archive/20251005_0350.html">20251005_0350</a>
<a href="archive/20251004_0352.html">20251004_0352</a>
<a href="archive/20251003_0352.html">20251003_0352</a>
<a href="archive/20251002_0356.html">20251002_0356</a>
<a href="archive/20251001_0321.html">20251001_0321</a>
<a href="archive/20250925_0335.html">20250925_0335</a>
<a href="archive/20250924_0350.html">20250924_0350</a>
<a href="archive/20250923_0348.html">20250923_0348</a>
<a href="archive/20250922_0346.html">20250922_0346</a>
<a href="archive/20250921_0345.html">20250921_0345</a>
<a href="archive/20250920_0342.html">20250920_0342</a>
<a href="archive/20250919_0346.html">20250919_0346</a>
<a href="archive/20250918_0342.html">20250918_0342</a>
<a href="archive/20250917_0336.html">20250917_0336</a>
<a href="archive/20250916_0333.html">20250916_0333</a>
<a href="archive/20250915_0333.html">20250915_0333</a>
<a href="archive/20250914_0328.html">20250914_0328</a>
<a href="archive/20250913_0322.html">20250913_0322</a>
<a href="archive/20250912_0335.html">20250912_0335</a>
<a href="archive/20250911_0337.html">20250911_0337</a>
<a href="archive/20250910_0338.html">20250910_0338</a>
<a href="archive/20250909_0341.html">20250909_0341</a>
<a href="archive/20250908_0342.html">20250908_0342</a>
<a href="archive/20250907_0333.html">20250907_0333</a>
<a href="archive/20250906_0350.html">20250906_0350</a>
<a href="archive/20250905_0319.html">20250905_0319</a>
<a href="archive/20250904_0323.html">20250904_0323</a>
<a href="archive/20250903_0355.html">20250903_0355</a>
<a href="archive/20250902_0325.html">20250902_0325</a>
<a href="archive/20250901_0355.html">20250901_0355</a>
<a href="archive/20250831_0355.html">20250831_0355</a>
<a href="archive/20250830_0356.html">20250830_0356</a>
<a href="archive/20250829_0355.html">20250829_0355</a>
<a href="archive/20250828_0333.html">20250828_0333</a>
<a href="archive/20250827_1654.html">20250827_1654</a>
<a href="archive/20250827_1602.html">20250827_1602</a>
<a href="archive/20250827_1557.html">20250827_1557</a>
<a href="archive/20250827_0320.html">20250827_0320</a>
<a href="archive/20250826_0320.html">20250826_0320</a>
<a href="archive/20250825_1752.html">20250825_1752</a>
<a href="archive/20250825_1709.html">20250825_1709</a>
<a href="archive/20250825_1652.html">20250825_1652</a>
<a href="archive/20250825_1647.html">20250825_1647</a>
<a href="archive/20250825_1645.html">20250825_1645</a>
<a href="archive/20250825_1631.html">20250825_1631</a>
<a href="archive/20250825_1606.html">20250825_1606</a>
<a href="archive/20250825_1559.html">20250825_1559</a>
<a href="archive/20250825_1558.html">20250825_1558</a>
<a href="archive/20250825_1556.html">20250825_1556</a>
<a href="archive/20250825_1531.html">20250825_1531</a>
<a href="archive/20250825_1525.html">20250825_1525</a>
<a href="archive/20250825_1516.html">20250825_1516</a>
<a href="archive/20250825_1450.html">20250825_1450</a>
<a href="archive/20250825_1444.html">20250825_1444</a>
<a href="archive/20250825_1438.html">20250825_1438</a>
<a href="archive/20250825_1414.html">20250825_1414</a>
<a href="archive/20250825_1413.html">20250825_1413</a>
<a href="archive/20250825_1410.html">20250825_1410</a>
<a href="archive/20250825_1408.html">20250825_1408</a>
<a href="archive/20250825_1405.html">20250825_1405</a>
<a href="archive/20250825_1401.html">20250825_1401</a>
<a href="archive/20250825_1355.html">20250825_1355</a>
<a href="archive/20250825_1347.html">20250825_1347</a>
<a href="archive/20250825_1345.html">20250825_1345</a>
<a href="archive/20250825_1344.html">20250825_1344</a>
<a href="archive/20250825_1343.html">20250825_1343</a>
<a href="archive/20250825_1340.html">20250825_1340</a>
<a href="archive/20250825_1339.html">20250825_1339</a>
<a href="archive/20250825_1333.html">20250825_1333</a>
<a href="archive/20250825_1323.html">20250825_1323</a>
<a href="archive/20250825_1317.html">20250825_1317</a>
<a href="archive/20250825_1243.html">20250825_1243</a>
<a href="archive/20250824_0342.html">20250824_0342</a>
<a href="archive/20250823_0343.html">20250823_0343</a>
<a href="archive/20250823_0142.html">20250823_0142</a>
<a href="archive/20250822_2331.html">20250822_2331</a>
<a href="archive/20250822_2308.html">20250822_2308</a>
<a href="archive/20250822_2258.html">20250822_2258</a>
<a href="archive/20250822_2241.html">20250822_2241</a>
<a href="archive/20250822_2228.html">20250822_2228</a>
<a href="archive/20250822_2206.html">20250822_2206</a>
<a href="archive/20250822_2147.html">20250822_2147</a>
<a href="archive/20250822_2111.html">20250822_2111</a>
<a href="archive/20250822_1259.html">20250822_1259</a>
<a href="archive/20250822_1233.html">20250822_1233</a>
<a href="archive/20250822_1229.html">20250822_1229</a>
<a href="archive/20250822_1223.html">20250822_1223</a>
<a href="archive/20250822_1210.html">20250822_1210</a>
<a href="archive/20250822_1201.html">20250822_1201</a>
<a href="archive/20250822_1111.html">20250822_1111</a>
<a href="archive/20250822_1058.html">20250822_1058</a>
<a href="archive/20250822_1052.html">20250822_1052</a>
<a href="archive/20250822_1045.html">20250822_1045</a>
<a href="archive/20250822_0657.html">20250822_0657</a>
<a href="archive/20250822_0553.html">20250822_0553</a></div>
    </details>
    <div class="footer">Generated by arxiv-tracker</div>
  </div>
</body></html>
